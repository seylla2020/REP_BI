{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layout generator for Simba Report\n",
    "\n",
    "@Raphael Dayan -- analytics@mercadopago.com.br\n",
    "\n",
    "https://asspaweb.pgr.mpf.gov.br/site/index.php/sistemas/sigilo-bancario-simba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install http://pypi.ml.com/api/package/melitk-analytics/melitk.analytics-1.4.0.tar.gz\n",
    "#!pip install -i http://pypi.ml.com/simple/melitk-analytics/melitk.analytics-1.4.0.tar.gz\n",
    "#!pip install openpyxl\n",
    "#!pip install -i http://pypi.ml.com/simple/ melitk-fda --trusted-host pypi.ml.com\n",
    "#!pip install -i http://pypi.ml.com/simple/ melitk-analytics --trusted-host pypi.ml.com\n",
    "\n",
    "from datetime import date\n",
    "import datetime as dt\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import numpy as np\n",
    "import csv\n",
    "import openpyxl\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from melitk.analytics.connectors.core.authentication import Authentication\n",
    "from melitk.analytics.connectors.teradata import ConnTeradata\n",
    "from melitk.fda import workspace\n",
    "\n",
    "teradata_user = os.environ['SECRET_TERADATA_USER']\n",
    "teradata_pass = os.environ['SECRET_TERADATA_PASS']\n",
    "tera = ConnTeradata(teradata_user, teradata_pass, auth_method=Authentication.APP)\n",
    "print('Connection has started at', dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CSV File for newly created Oficios\n",
    "print('Import has been started at', dt.datetime.now())\n",
    "csv_file = '/alloc/data/fury_oficios-quebra-sigilo/notebooks/csv_r.csv'\n",
    "csv_oficios = pd.read_csv(csv_file, engine='python', sep = ';', parse_dates=['DATA_OFICIO', 'RANGE_MIN', 'RANGE_MAX', 'CREATED_AT'], encoding = 'iso-8859-1',  converters={'DOC_NUMBER': lambda x: str(x),\n",
    "                                                                                                                                                                          'NUMERO_PROCESSO': lambda x: str(x)})\n",
    "csv_oficios = csv_oficios.astype(str)\n",
    "print('File has been processed and can be used at', dt.datetime.now())\n",
    "#csv_oficios['DOC_NUMBER'].str.len().drop_duplicates() # to check len\n",
    "#csv_oficios['CREATED_AT'].drop_duplicates() \n",
    "#csv_oficios[csv_oficios['DOC_NUMBER'].str.len() == 13]\n",
    "#csv_oficios[~csv_oficios['DOC_NUMBER'].str.isdigit()]\n",
    "#csv_oficios['DATA_OFICIO'].drop_duplicates() \n",
    "#csv_oficios['RANGE_MIN'].drop_duplicates() \n",
    "#csv_oficios['RANGE_MAX'].drop_duplicates() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create excel table if needed. Otherwise use insert below\n",
    "# counter = 1 \n",
    "# with open(\"./Queries/create_csv_table.sql\", \"r\") as f:\n",
    "#    create_csv_table = f.read().split(\";\")[:-1]\n",
    "#   total_queries = str(len(create_csv_table))\n",
    "# print('Total queries to run: ' + total_queries + '\\n')\n",
    "\n",
    "#     for query in create_csv_table:\n",
    "#         print('Running query #', counter, 'out of ' + total_queries + query[:50], '...')\n",
    "#         start_query = time.time()\n",
    "#         print('Querying process started at', dt.datetime.now())\n",
    "#         tera.execute(query)\n",
    "#         end_query = time.time()\n",
    "#         print('Querying took %1.2f' %(end_query-start_query), 'seconds to run.')\n",
    "#         print('Querying process ended at', dt.datetime.now(), '\\n')\n",
    "#         counter +=1\n",
    "#         clear_output()\n",
    "\n",
    "# Insert new rows into documents to be reported log\n",
    "print('Insert has been started at', dt.datetime.now())\n",
    "start_query = time.time()\n",
    "df = csv_oficios\n",
    "data = df.values.tolist()\n",
    "for i in range(0,len(df),1000):\n",
    "    insert_query = ''\n",
    "    for j in range(1000):\n",
    "        if (i + j) < len(df):            \n",
    "            insert_query += \"\"\"INSERT MP_MPB.DOC_INPUT values ('{}','{}','{}','{}','{}','{}','{}','{}','{}','{}','{}','{}');\"\"\".format(*data[i+j])\n",
    "    tera.execute(insert_query)\n",
    "end_query = time.time()\n",
    "print('Insert took %1.2f' %(end_query-start_query), 'seconds to run.')\n",
    "print('File has been processed and can be used at', dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Create matched doc info to be used as parameter to search ranges if needed. Otherwise use insert below\n",
    "# with open(\"./Queries/doc_info_match.sql\", \"r\") as f:\n",
    "#     doc_info_match_response = f.read().split(\";\")[:-1]\n",
    "    \n",
    "#     for query in doc_info_match_response:\n",
    "#         tera.execute(query)\n",
    "\n",
    "# Insert doc info match\n",
    "with open(\"./Queries/insert_doc_info_match.sql\", \"r\") as f:\n",
    "    insert_doc_info_match_response = f.read().split(\";\")[:-1]\n",
    "    \n",
    "    for query in insert_doc_info_match_response:\n",
    "        tera.execute(query)\n",
    "print('Has run at', dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Account Movement History Log\n",
    "with open(\"./Queries/account_movement.sql\", \"r\") as f:\n",
    "    account_movement_response = f.read().split(\";\")[:-1]\n",
    "    \n",
    "    for query in account_movement_response:\n",
    "        tera.execute(query)\n",
    "print('Has run at', dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query1=pd.DataFrame(tera.execute_response('select * from MP_MPB.ACC_MOV_HISTORY_TEMP sample 10'))\n",
    "#query1=pd.DataFrame(tera.execute_response('SELECT * FROM MP_MPB.DOC_INPUT'))\n",
    "#query1\n",
    "#query1=pd.DataFrame(tera.execute_response('SELECT DISTINCT CUS_CUST_ID FROM MP_MPB.DOC_INPUT_MATCH WHERE CREATED_AT = (SELECT MAX(CREATED_AT) FROM MP_MPB.DOC_INPUT)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Withdrawal History Log \n",
    "with open(\"./Queries/withdrawal_movement.sql\", \"r\") as f:\n",
    "    account_movement_response = f.read().split(\";\")[:-1]\n",
    "    \n",
    "    for query in account_movement_response:\n",
    "        tera.execute(query)\n",
    "print('Has run at', dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join Movements + Withdrawal\n",
    "with open(\"./Queries/joined_mov_history.sql\", \"r\") as f:\n",
    "    joined_movement_response = f.read().split(\";\")[:-1]\n",
    "    \n",
    "    for query in joined_movement_response:\n",
    "        tera.execute(query)\n",
    "print('Has run at', dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab docs with their ranges to report\n",
    "with open(\"./Queries/doc_info_ranges.sql\", \"r\") as f:\n",
    "    custs_response = f.read().split(\";\")[:-1]\n",
    "    \n",
    "    for query in custs_response:\n",
    "        custs = tera.execute_response(query)\n",
    "        custs = pd.DataFrame(custs)\n",
    "        custs_range = custs[['COMPUTADOR_DESTINO', 'NUMERO_CASO', 'CUS_CUST_ID', 'RANGE_MIN', 'RANGE_MAX', 'CREATED_AT']]\n",
    "        custs_range['OFICIO_NUMBER'] = custs[['COMPUTADOR_DESTINO', 'NUMERO_CASO']].apply(lambda x: '-'.join(x), axis=1)\n",
    "        custs_range = custs_range.astype({\"CUS_CUST_ID\": int})\n",
    "        custs_range = custs_range.astype({\"OFICIO_NUMBER\": str})\n",
    "        custs_range = custs_range[['OFICIO_NUMBER',  'CREATED_AT', 'CUS_CUST_ID', 'RANGE_MIN', 'RANGE_MAX']]\n",
    "        #custs_range = custs_range.head(50)\n",
    "print('Has run at', dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table with each customer suit-tailored range \n",
    "with open(\"./Queries/create_movement_table.sql\", \"r\") as f:\n",
    "    mov_response = f.read().split(\";\")[:-1]\n",
    "    \n",
    "    for query in mov_response:\n",
    "        tera.execute(query)\n",
    "print('Has run at', dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert into table each Oficios Number and customer ranges\n",
    "cust_ranges_list = []\n",
    "for param in custs_range.values.tolist():\n",
    "    cust_ranges_list.append(\n",
    "\"\"\"    \n",
    "INSERT INTO MP_MPB.ACC_MOV_HISTORY_REPORT\n",
    "SELECT\n",
    "      CUS_CUST_ID,\n",
    "      CUS_CUST_ID_SEL,\n",
    "      CUS_CUST_ID_BUY,\n",
    "      MOV_MOVE_ID,\n",
    "      MOV_CREATED_DT,\n",
    "      MOV_DETAIL,\n",
    "      MOV_TYPE_ID,\n",
    "      PAY_PAYMENT_ID,\n",
    "      PAY_REASON_ID,\n",
    "      PAY_OPERATION_TYPE_ID,\n",
    "      MOV_FINANCIAL_ENTITY_ID,\n",
    "      WIT_WITHDRAW_ID,\n",
    "      MOV_AMOUNT,\n",
    "      ACCOUNT_TYPE,\n",
    "      WIT_BANK_ACC_NUMBER,\n",
    "      WITHDRAWAL_STATUS,\n",
    "      RECEIVING_ACCOUNT_HOLDER_NAME,\n",
    "      RECEIVING_ACCOUNT_HOLDER_DOC_NUMBER,\n",
    "      BANK_ID,\n",
    "      WIT_BANK_ACC_BRANCH_ID,\n",
    "      RECEIVING_BANK_NAME,\n",
    "      PAYER_BANK_NAME,\n",
    "      WITHDRAWAL_METHOD,\n",
    "      WITHDRAWAL_AMOUNT,\n",
    "      CAST('{oficio_number}' AS VARCHAR(400)) AS OFICIO_NUMBER,\n",
    "      CAST('{oficio_created_at}' AS VARCHAR(400)) AS OFICIO_CREATED_AT\n",
    "FROM MP_MPB.USER_MOV_HISTORY\n",
    "WHERE 1=1\n",
    "      AND CUS_CUST_ID = {cust_id}\n",
    "      AND MOV_CREATED_DT BETWEEN '{range_min}' AND '{range_max}'\n",
    "\"\"\".format(oficio_number = param[0], oficio_created_at = param[1], cust_id = param[2], range_min = param[3], range_max = param[4]) + \";\"\n",
    ")\n",
    "    \n",
    "counter = 1\n",
    "total_queries = str(len(cust_ranges_list))\n",
    "print('Total queries to run: ' + total_queries + '\\n')\n",
    "\n",
    "for query in cust_ranges_list:\n",
    "    print('Running query #', counter, 'out of ' + total_queries + query[:50], '...')\n",
    "    start_query = time.time()\n",
    "    print('Querying process started at', dt.datetime.now())\n",
    "    tera.execute(query)\n",
    "    end_query = time.time()\n",
    "    print('Querying took %1.2f' %(end_query-start_query), 'seconds to run.')\n",
    "    print('Querying process ended at', dt.datetime.now(), '\\n')\n",
    "    counter +=1\n",
    "    clear_output()\n",
    "    \n",
    "print('Has run at', dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create customer info table\n",
    "with open(\"./Queries/cus_info.sql\", \"r\") as f:\n",
    "    customer_response = f.read().split(\";\")[:-1]\n",
    "    \n",
    "    for query in customer_response:\n",
    "        tera.execute(query)\n",
    "print('Has run at', dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # Create report log table if needed. Otherwise use insert below\n",
    "# with open(\"./Queries/create_oficios_table.sql\", \"r\") as f:\n",
    "#     oficios_create_response = f.read().split(\";\")[:-1]\n",
    "    \n",
    "#     for query in oficios_create_response:\n",
    "#         tera.execute(query)\n",
    "\n",
    "# Insert info @log table\n",
    "with open(\"./Queries/insert_oficios_table.sql\", \"r\") as f:\n",
    "    oficios_insert_response = f.read().split(\";\")[:-1]\n",
    "    \n",
    "    for query in oficios_insert_response:\n",
    "        tera.execute(query)\n",
    "print('Has run at', dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log table to start data cleansing and layout development\n",
    "with open(\"./Queries/oficios_db.sql\", \"r\") as f:\n",
    "    oficios_db_response = f.read().split(\";\")[:-1]\n",
    "    \n",
    "    for query in oficios_db_response:\n",
    "        oficios_tbl = tera.execute_response(query)\n",
    "        oficios_df = pd.DataFrame(oficios_tbl)\n",
    "        #oficios_df = oficios_df.head(50)\n",
    "        #oficios_df = oficios_df[oficios_df['OFICIO_NUMBER'] == \"059-PCRO-000028-45\"]\n",
    "        #of = [\"093\"O-000261-69\",\"001-MPF-004416-70\",\"061-PCCE-000078-00\",\"001-MPF-004469-81\",\"018-PCSP-000554-55\",\"001-MPF-004350-09\"]\n",
    "        #oficios_df = oficios_df[oficios_df.OFICIO_NUMBER.isin(of)]\n",
    "print(oficios_df.shape, dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oficios information to send emails + csvs\n",
    "with open(\"./Queries/oficios_info.sql\", \"r\") as f:\n",
    "    oficios_info_response = f.read().split(\";\")[:-1]\n",
    "    \n",
    "    for query in oficios_info_response:\n",
    "        oficios_info_tbl = tera.execute_response(query)\n",
    "        oficios_info_df = pd.DataFrame(oficios_info_tbl)\n",
    "        #oficios_info_df =  oficios_info_df[oficios_info_df['OFICIO_NUMBER'] == \"059-PCRO-000028-45\"]\n",
    "        #oficios_info_df = oficios_info_df[oficios_info_df.OFICIO_NUMBER.isin(of)]\n",
    "print(oficios_info_df.shape, dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doc number range to fill investigados.txt\n",
    "with open(\"./Queries/investigados_doc_range.sql\", \"r\") as f:\n",
    "    doc_info_response = f.read().split(\";\")[:-1]\n",
    "    \n",
    "    for query in doc_info_response:\n",
    "        doc_info_tbl = tera.execute_response(query)\n",
    "        doc_info_df = pd.DataFrame(doc_info_tbl)\n",
    "        #doc_info_df = doc_info_df[doc_info_df['OFICIO_NUMBER'] == \"059-PCRO-000028-45\"]\n",
    "        #doc_info_df = doc_info_df[doc_info_df.OFICIO_NUMBER.isin(of)]\n",
    "        doc_info_df.rename(columns = {'DOC_NUMBER': 'CUS_CUST_DOC_NUMBER'}, inplace = True)\n",
    "print(doc_info_df.shape, dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agencias['HAD_REPORT'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting generation of 'AGENCIAS' layout\n",
    "agencias = oficios_df[['OFICIO_NUMBER', 'BANK_ID', 'WIT_BANK_ACC_BRANCH_ID', 'RECEIVING_BANK_NAME', 'CUS_RU_SINCE_DT_BUY', 'HAD_REPORT']].drop_duplicates()\n",
    "agencias['OFICIO_NUMBER'] = agencias['OFICIO_NUMBER']\n",
    "agencias['HAD_REPORT'] = agencias['HAD_REPORT']\n",
    "#agencias['NUMERO_BANCO'] = agencias['BANK_ID'].fillna('033')\n",
    "agencias['NUMERO_BANCO'] = \"323\"\n",
    "#agencias['NUMERO_AGENCIA'] = agencias['WIT_BANK_ACC_BRANCH_ID'].fillna('2167')\n",
    "agencias['NUMERO_AGENCIA'] = \"0001\"\n",
    "#agencias['NOME_AGENCIA'] = agencias['RECEIVING_BANK_NAME'].fillna('Mercado Pago')\n",
    "agencias['NOME_AGENCIA'] = \"Mercado Pago\"\n",
    "#agencias['ENDERECO_LOGRADOURO'] = np.where(agencias['NUMERO_BANCO'] == \"033\", 'AVENIDA DAS NACOES UNIDAS, 3003', 'Nao ha endereco logradouro')\n",
    "agencias['ENDERECO_LOGRADOURO'] = \"AVENIDA DAS NACOES UNIDAS, 3003\"\n",
    "#agencias['ENDERECO_CIDADE'] = np.where(agencias['NUMERO_BANCO'] == \"033\", 'OSASCO', 'Nao ha endereco cidade')\n",
    "agencias['ENDERECO_CIDADE'] = \"OSASCO\"\n",
    "#agencias['ENDERECO_UF'] = np.where(agencias['NUMERO_BANCO'] == \"033\", 'SP', 'XX')\n",
    "agencias['ENDERECO_UF'] = \"SP\"\n",
    "#agencias['ENDERECO_PAIS'] = np.where(agencias['NUMERO_BANCO'] == \"033\", 'BRASIL', 'BRASIL')\n",
    "agencias['ENDERECO_PAIS'] = \"BRASIL\"\n",
    "#agencias['ENDERECO_CEP'] = np.where(agencias['NUMERO_BANCO'] == \"033\", '06233903', '00000000')\n",
    "agencias['ENDERECO_CEP'] = \"06233903\"\n",
    "#agencias['TELEFONE_AGENCIA'] = np.where(agencias['NUMERO_BANCO'] == \"033\", '1125434155', '0000000000')\n",
    "agencias['TELEFONE_AGENCIA'] = \"1125434155\"\n",
    "agencias['DATA_ABERTURA_AGENCIA'] = np.where(agencias['NUMERO_BANCO'] == \"033\", '22122008', agencias['CUS_RU_SINCE_DT_BUY'].fillna('00000000')) #13062019\n",
    "agencias['DATA_ABERTURA_AGENCIA'] = \"22122008\"\n",
    "agencias['DATA_FECHAMENTO_AGENCIA'] = \"\"\n",
    "agencias = agencias[['HAD_REPORT', 'OFICIO_NUMBER', 'NUMERO_BANCO', 'NUMERO_AGENCIA', 'NOME_AGENCIA', \n",
    "                     'ENDERECO_LOGRADOURO', 'ENDERECO_CIDADE',\n",
    "                     'ENDERECO_UF', 'ENDERECO_PAIS', 'ENDERECO_CEP', \n",
    "                     'TELEFONE_AGENCIA', 'DATA_ABERTURA_AGENCIA', 'DATA_FECHAMENTO_AGENCIA']].drop_duplicates()\n",
    "agencias_df = pd.DataFrame(agencias)\n",
    "\n",
    "# Correcting 'AGENCIAS' layout\n",
    "    # NUMERO_BANCO = 3 char\n",
    "    # NUMERO_AGENCIA = 4 char\n",
    "    # NOME_AGENCIA = 50 char\n",
    "    # ENDERECO_LOGRADOURO = 80 char\n",
    "    # ENDERECO_CIDADE = 40 char\n",
    "    # ENDERECO_UF = 2 char\n",
    "    # ENDERECO_PAIS = 40 char\n",
    "    # ENDERECO_CEP = 8 char\n",
    "    # TELEFONE_AGENCIA = 20 char\n",
    "    # DATA_ABERTURA_AGENCIA = 8 char, DDMMYYYY\n",
    "    # DATA_FECHAMENTO_AGENCIA = 8 char, DDMMYYYY\n",
    "\n",
    "agencias_df['NUMERO_BANCO'] = agencias_df['NUMERO_BANCO'].str.ljust(3, ' ')\n",
    "agencias_df['NUMERO_AGENCIA'] = agencias_df['NUMERO_AGENCIA'].str.ljust(4, ' ')\n",
    "agencias_df['NOME_AGENCIA'] = agencias_df['NOME_AGENCIA'].str.ljust(50, ' ')\n",
    "agencias_df['ENDERECO_LOGRADOURO'] = agencias_df['ENDERECO_LOGRADOURO'].str.ljust(80, ' ')\n",
    "agencias_df['ENDERECO_CIDADE'] = agencias_df['ENDERECO_CIDADE'].str.ljust(40, ' ')\n",
    "agencias_df['ENDERECO_UF'] = agencias_df['ENDERECO_UF'].str.ljust(2, ' ')\n",
    "agencias_df['ENDERECO_PAIS'] = agencias_df['ENDERECO_PAIS'].str.ljust(40, ' ')\n",
    "agencias_df['ENDERECO_CEP'] = agencias_df['ENDERECO_CEP'].str.ljust(8, ' ')\n",
    "agencias_df['TELEFONE_AGENCIA'] = agencias_df['TELEFONE_AGENCIA'].str.ljust(20, ' ')\n",
    "agencias_df['DATA_ABERTURA_AGENCIA'] = agencias_df['DATA_ABERTURA_AGENCIA'].str.ljust(8, ' ') \n",
    "agencias_df['DATA_FECHAMENTO_AGENCIA'] = agencias_df['DATA_FECHAMENTO_AGENCIA'].str.ljust(8, ' ')\n",
    "agencias_df = agencias_df[agencias_df['NUMERO_BANCO'] == \"323\"]\n",
    "# agencias_df['ENDERECO_PAIS'].str.len().drop_duplicates() # to check len\n",
    "\n",
    "# Generating archive names + rows\n",
    "column_names = [\"REPORT\", \"NOME_ARQUIVO\", \"LINHA_ARQUIVO\"]\n",
    "agencias_df_txt = pd.DataFrame(columns = column_names)\n",
    "agencias_df_txt['REPORT'] = agencias_df['HAD_REPORT']\n",
    "agencias_df_txt['NOME_ARQUIVO'] = agencias_df['OFICIO_NUMBER']\n",
    "agencias_df_txt['LINHA_ARQUIVO'] = agencias_df[['NUMERO_BANCO', 'NUMERO_AGENCIA', 'NOME_AGENCIA', \n",
    "                     'ENDERECO_LOGRADOURO', 'ENDERECO_CIDADE',\n",
    "                     'ENDERECO_UF', 'ENDERECO_PAIS', 'ENDERECO_CEP', \n",
    "                     'TELEFONE_AGENCIA', 'DATA_ABERTURA_AGENCIA', 'DATA_FECHAMENTO_AGENCIA']].apply(lambda x: '\\t'.join(x), axis=1)\n",
    "agencias_df_txt = agencias_df_txt[agencias_df_txt['REPORT'] == \"002\"]\n",
    "agencias_df_csv = agencias_df.merge(oficios_info_df, on='OFICIO_NUMBER', how='left')\n",
    "agencias_df_csv = agencias_df_csv[agencias_df_csv['HAD_REPORT'] == \"002\"] \n",
    "agencias_df_csv = agencias_df_csv.astype({'HAD_REPORT': str,\n",
    "                                          'OFICIO_NUMBER': str,\n",
    "                                          'NUMERO_BANCO': str,\n",
    "                                          'NUMERO_AGENCIA': str,\n",
    "                                          'NOME_AGENCIA': str,\n",
    "                                          'ENDERECO_LOGRADOURO': str,\n",
    "                                          'ENDERECO_CIDADE': str,\n",
    "                                          'ENDERECO_UF': str,\n",
    "                                          'ENDERECO_PAIS': str,\n",
    "                                          'ENDERECO_CEP': str,\n",
    "                                          'TELEFONE_AGENCIA': str,\n",
    "                                          'DATA_ABERTURA_AGENCIA': str,\n",
    "                                          'DATA_FECHAMENTO_AGENCIA': str,\n",
    "                                          'CARGO_MAGISTRADO': str,\n",
    "                                          'DATA_OFICIO': str,\n",
    "                                          'EMAIL_CASO': str,\n",
    "                                          'NOME_MAGISTRADO': str,\n",
    "                                          'NOME_TRIBUNAL': str,\n",
    "                                          'NUMERO_PROCESSO': str})\n",
    "print('Job has finished sucessfully', dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating 'AGENCIAS' .txt\n",
    "for row in agencias_df_txt.groupby('NOME_ARQUIVO'):\n",
    "    row[1]['LINHA_ARQUIVO'].to_csv('/alloc/data/fury_oficios-quebra-sigilo/notebooks/Archives/'+str(row[0]).strip('[]').strip(\"'\")+'_AGENCIAS.txt', \n",
    "                                      index = False, \n",
    "                                      header = False,\n",
    "                                      quotechar= \"\",\n",
    "                                      sep = \"\\n\",\n",
    "                                      escapechar = '\\\\',\n",
    "                                      quoting=csv.QUOTE_NONE)\n",
    "\n",
    "# Create excel file with sheet = AGENCIAS to be sent @email.\n",
    "agencias_grouped = agencias_df_csv.groupby('OFICIO_NUMBER')\n",
    "for ag_titles, ag_rows in agencias_grouped:\n",
    "    with pd.ExcelWriter('/alloc/data/fury_oficios-quebra-sigilo/notebooks/Archives/'+str(ag_titles)+'.xlsx') as writer:  \n",
    "        ag_rows.to_excel(writer, sheet_name='AGENCIAS', index= False, header = True)\n",
    "\n",
    "# If you want to save it separately as .csv\n",
    "# agencias_grouped = agencias_df_csv.groupby('OFICIO_NUMBER')\n",
    "# for titles, rows in agencias_grouped:\n",
    "#     rows.to_csv('/alloc/data/fury_oficios-quebra-sigilo/notebooks/Arquivos/'+str(titles)+'.csv',\n",
    "#                                       index = False,\n",
    "#                                       header= True)\n",
    "print('Job has finished sucessfully', dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting generation of 'CONTAS' layout\n",
    "contas = oficios_df[['OFICIO_NUMBER', 'BANK_ID', 'WIT_BANK_ACC_BRANCH_ID', 'WIT_BANK_ACC_NUMBER', 'ACCOUNT_TYPE', 'HAD_REPORT']].drop_duplicates()\n",
    "contas['OFICIO_NUMBER'] = contas['OFICIO_NUMBER']\n",
    "contas['HAD_REPORT'] = contas['HAD_REPORT']\n",
    "#contas['NUMERO_BANCO'] = contas['BANK_ID'].fillna('033')\n",
    "contas['NUMERO_BANCO'] = \"323\"\n",
    "#contas['NUMERO_AGENCIA'] = contas['WIT_BANK_ACC_BRANCH_ID'].fillna('2167')\n",
    "contas['NUMERO_AGENCIA'] = \"0001\"\n",
    "#contas['NUMERO_CONTA'] = contas['WIT_BANK_ACC_NUMBER'].fillna('130010391')\n",
    "contas['NUMERO_CONTA'] = \"10573521\"\n",
    "# contas['TIPO_CONTA'] = np.where(contas['NUMERO_BANCO'] == \"323\", '4',\n",
    "#                   np.where(contas['ACCOUNT_TYPE'] == \"checking_account\", '1',\n",
    "#                   np.where(contas['ACCOUNT_TYPE'] == \"savings_account\", '2', '4')))\n",
    "contas['TIPO_CONTA'] = \"4\"\n",
    "#contas['DATA_ABERTURA_CONTA'] = np.where(contas['NUMERO_BANCO'] == \"323\", '22122008', '')\n",
    "contas['DATA_ABERTURA_CONTA'] = \"22122008\"\n",
    "contas['DATA_ENCERRAMENTO_CONTA'] = \"\"\n",
    "contas['MOVIMENTACAO_CONTA'] = '1'\n",
    "contas = contas[['HAD_REPORT', 'OFICIO_NUMBER', 'NUMERO_BANCO', 'NUMERO_AGENCIA', \n",
    "                  'NUMERO_CONTA', 'TIPO_CONTA',\n",
    "                  'DATA_ABERTURA_CONTA', 'DATA_ENCERRAMENTO_CONTA',\n",
    "                  'MOVIMENTACAO_CONTA']].drop_duplicates()\n",
    "contas_df = pd.DataFrame(contas)\n",
    "\n",
    "# Correcting 'CONTAS' layout\n",
    "    # NUMERO_BANCO = 3 char\n",
    "    # NUMERO_AGENCIA = 4 char\n",
    "    # NUMERO_CONTA = 20 char\n",
    "    # TIPO_CONTA = 1 char\n",
    "    # DATA_ABERTURA_CONTA = 8 char, DDMMYYYY\n",
    "    # DATA_ENCERRAMENTO_CONTA = 8 char, DDMMYYYY\n",
    "    # MOVIMENTACAO_CONTA =  1 char\n",
    "\n",
    "contas_df['NUMERO_BANCO'] = contas_df['NUMERO_BANCO'].str.ljust(3, ' ')\n",
    "contas_df['NUMERO_AGENCIA'] = contas_df['NUMERO_AGENCIA'].str.ljust(4, ' ')\n",
    "contas_df['NUMERO_CONTA'] = contas_df['NUMERO_CONTA'].str.ljust(20, ' ')\n",
    "contas_df['TIPO_CONTA'] = contas_df['TIPO_CONTA'].str.ljust(1, ' ')\n",
    "contas_df['DATA_ABERTURA_CONTA'] = contas_df['DATA_ABERTURA_CONTA'].str.ljust(8, ' ') \n",
    "contas_df['DATA_ENCERRAMENTO_CONTA'] = contas_df['DATA_ENCERRAMENTO_CONTA'].str.ljust(8, ' ')\n",
    "contas_df = contas_df[contas_df['NUMERO_BANCO'] == \"323\"]\n",
    "# contas_df['NUMERO_CONTA'].str.len().drop_duplicates() # to check len\n",
    "\n",
    "# Generating archive names + rows\n",
    "column_names = [\"REPORT\", \"NOME_ARQUIVO\", \"LINHA_ARQUIVO\"]\n",
    "contas_df_txt = pd.DataFrame(columns = column_names)\n",
    "contas_df_txt['REPORT'] = contas_df['HAD_REPORT']\n",
    "contas_df_txt['NOME_ARQUIVO'] = contas_df['OFICIO_NUMBER']\n",
    "contas_df_txt['LINHA_ARQUIVO'] = contas_df[['NUMERO_BANCO', 'NUMERO_AGENCIA', \n",
    "                  'NUMERO_CONTA', 'TIPO_CONTA',\n",
    "                  'DATA_ABERTURA_CONTA', 'DATA_ENCERRAMENTO_CONTA',\n",
    "                  'MOVIMENTACAO_CONTA']].apply(lambda x: '\\t'.join(x), axis=1)\n",
    "contas_df_txt = contas_df_txt[contas_df_txt['REPORT'] == \"002\"]\n",
    "contas_df_csv = contas_df.merge(oficios_info_df, on='OFICIO_NUMBER', how='left')\n",
    "contas_df_csv = contas_df_csv[contas_df_csv['HAD_REPORT'] == \"002\"]\n",
    "contas_df_csv = contas_df_csv.astype({'HAD_REPORT': str,\n",
    "                                          'OFICIO_NUMBER': str,\n",
    "                                          'NUMERO_BANCO': str,\n",
    "                                          'NUMERO_AGENCIA': str,\n",
    "                                          'NUMERO_CONTA': str,\n",
    "                                          'TIPO_CONTA': str,\n",
    "                                          'DATA_ABERTURA_CONTA': str,\n",
    "                                          'DATA_ENCERRAMENTO_CONTA': str,\n",
    "                                          'MOVIMENTACAO_CONTA': str,\n",
    "                                          'CARGO_MAGISTRADO': str,\n",
    "                                          'DATA_OFICIO': str,\n",
    "                                          'EMAIL_CASO': str,\n",
    "                                          'NOME_MAGISTRADO': str,\n",
    "                                          'NOME_TRIBUNAL': str,\n",
    "                                          'NUMERO_PROCESSO': str})\n",
    "print('Job has finished sucessfully', dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating 'CONTAS' .txt\n",
    "for row in contas_df_txt.groupby('NOME_ARQUIVO'):\n",
    "    row[1]['LINHA_ARQUIVO'].to_csv('/alloc/data/fury_oficios-quebra-sigilo/notebooks/Archives/'+str(row[0]).strip('[]').strip(\"'\")+'_CONTAS.txt', \n",
    "                                      index = False, \n",
    "                                      header = False,\n",
    "                                      quotechar= \"\",\n",
    "                                      sep = \"\\n\",\n",
    "                                      escapechar = '\\\\',\n",
    "                                      quoting=csv.QUOTE_NONE)\n",
    "\n",
    "# Append excel file with sheet = CONTAS to be sent @email.\n",
    "contas_grouped = contas_df_csv.groupby('OFICIO_NUMBER')\n",
    "for co_titles, co_rows in contas_grouped:\n",
    "    with pd.ExcelWriter('/alloc/data/fury_oficios-quebra-sigilo/notebooks/Archives/'+str(co_titles)+'.xlsx',  mode='a') as writer:  \n",
    "        co_rows.to_excel(writer, sheet_name='CONTAS', index= False, header = True)\n",
    "\n",
    "print('Job has finished sucessfully', dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting generation of 'TITULARES' layout\n",
    "titulares = oficios_df[['OFICIO_NUMBER', 'BANK_ID', 'WIT_BANK_ACC_BRANCH_ID', 'WIT_BANK_ACC_NUMBER', 'ACCOUNT_TYPE', \n",
    "                        'CUS_CUST_DOC_NUMBER', 'CUS_FULL_NAME', 'CUS_CUST_DOC_TYPE',\n",
    "                        'CUS_ADDRESS','CUS_CITY', 'UF',\n",
    "                        'CUS_ZIP_CODE', 'CUS_RU_SINCE_DT', 'HAD_REPORT']].drop_duplicates()\n",
    "titulares = titulares[~titulares['CUS_CUST_DOC_NUMBER'].isna()]\n",
    "\n",
    "cus_full_name = titulares[['CUS_FULL_NAME','CUS_ADDRESS','CUS_CITY', 'UF',\n",
    "                        'CUS_ZIP_CODE', 'CUS_RU_SINCE_DT']].groupby(titulares['CUS_CUST_DOC_NUMBER']).nth(0).reset_index()\n",
    "\n",
    "cus_full_name['CUS_FULL_NAME_CORRECTED'] = cus_full_name['CUS_FULL_NAME']\n",
    "cus_full_name['CUS_ADDRESS_CORRECTED'] = cus_full_name['CUS_ADDRESS']\n",
    "cus_full_name['CUS_CITY_CORRECTED'] = cus_full_name['CUS_CITY']\n",
    "cus_full_name['UF_CORRECTED'] = cus_full_name['UF']\n",
    "cus_full_name['CUS_ZIP_CODE_CORRECTED'] = cus_full_name['CUS_ZIP_CODE']\n",
    "cus_full_name['CUS_RU_SINCE_DTCORRECTED'] = cus_full_name['CUS_RU_SINCE_DT']\n",
    "del cus_full_name['CUS_FULL_NAME']\n",
    "del cus_full_name['CUS_ADDRESS']\n",
    "del cus_full_name['CUS_CITY']\n",
    "del cus_full_name['UF']\n",
    "del cus_full_name['CUS_ZIP_CODE']\n",
    "del cus_full_name['CUS_RU_SINCE_DT']\n",
    "titulares = titulares.merge(cus_full_name, on=['CUS_CUST_DOC_NUMBER'], how = 'left')\n",
    "titulares['OFICIO_NUMBER'] = titulares['OFICIO_NUMBER']\n",
    "titulares['HAD_REPORT'] = titulares['HAD_REPORT']\n",
    "#titulares['NUMERO_BANCO'] = titulares['BANK_ID'].fillna('323')\n",
    "titulares['NUMERO_BANCO'] = \"323\"\n",
    "#titulares['NUMERO_AGENCIA'] = titulares['WIT_BANK_ACC_BRANCH_ID'].fillna('0001')\n",
    "titulares['NUMERO_AGENCIA'] = \"0001\"\n",
    "#titulares['NUMERO_CONTA'] = titulares['WIT_BANK_ACC_NUMBER'].fillna('00000000000000000000')\n",
    "titulares['NUMERO_CONTA'] = \"10573521\" \n",
    "# titulares['TIPO_CONTA'] = np.where(titulares['NUMERO_BANCO'] == \"323\", '4',\n",
    "#                    np.where(titulares['ACCOUNT_TYPE'] == \"checking_account\", '1',\n",
    "#                    np.where(titulares['ACCOUNT_TYPE'] == \"savings_account\", '2', '4')))\n",
    "titulares['TIPO_CONTA'] = \"4\"\n",
    "a = titulares[['CUS_CUST_DOC_NUMBER']].groupby(titulares['OFICIO_NUMBER']).nth(0).reset_index()\n",
    "a['flag'] = \"1\"\n",
    "titulares = titulares.merge(a, on= ['OFICIO_NUMBER', 'CUS_CUST_DOC_NUMBER'], how='left')\n",
    "titulares['TIPO_TITULAR'] = np.where(titulares['flag'] == \"1\", \"T\", \"O\")\n",
    "titulares['PESSOA_INVESTIGADA'] = np.where(titulares['HAD_REPORT'] == \"001\", \"0\", \"1\")\n",
    "titulares['TIPO_PESSOA_TITULAR'] = np.where(titulares['CUS_CUST_DOC_TYPE'].isna(), \n",
    "                        np.where(titulares['CUS_CUST_DOC_NUMBER'].fillna('').apply(len) == 11, '1', '2')\n",
    "                                 ,np.where(titulares['CUS_CUST_DOC_TYPE'] == \"CPF\", \"1\", \"2\"))\n",
    "titulares['CPF_CNPJ_TITULAR'] = titulares['CUS_CUST_DOC_NUMBER'].fillna('')\n",
    "titulares['NOME_TITULAR'] = titulares['CUS_FULL_NAME_CORRECTED'].fillna('Mercado Pago')\n",
    "titulares['NOME_DOC_IDENTIFICACAO'] = \"Nao ha documento extra\" # Preenchendo para testar\n",
    "titulares['NUMERO_DOC_IDENTIFICACAO'] = \"00000000000000000000\" # Preenchendo para testar\n",
    "titulares['ENDERECO_LOGRADOURO'] = titulares['CUS_ADDRESS_CORRECTED'].fillna('AVENIDA DAS NACOES UNIDAS, 3003')\n",
    "titulares['ENDERECO_CIDADE'] = titulares['CUS_CITY_CORRECTED'].fillna('SAO PAULO')\n",
    "titulares['ENDERECO_UF'] = titulares['UF_CORRECTED'].fillna('SP')\n",
    "titulares['ENDERECO_PAIS'] = \"BRASIL\"\n",
    "titulares['ENDERECO_CEP'] = titulares['CUS_ZIP_CODE_CORRECTED'].fillna('06233903')\n",
    "titulares['TELEFONE_PESSOA'] = \"00000000000\" # Preenchendo para testar\n",
    "titulares['VALOR_RENDA'] = \"00000000000000\" # Preenchendo para testar\n",
    "titulares['DATA_ATUALIZACAO_RENDA'] = '22122008' # titulares['CUS_RU_SINCE_DT_BUY'].fillna('') # Preenchendo para testar\n",
    "#titulares['DATA_INICIO_RELACIONAMENTO_CONTA'] = titulares['CUS_RU_SINCE_DT_BUY'].fillna('')\n",
    "#titulares['DATA_INICIO_RELACIONAMENTO_CONTA'] = np.where(titulares['NUMERO_BANCO'] == \"323\", '13062019',\n",
    "#                                                         titulares['CUS_RU_SINCE_DT_BUY'].fillna(''))\n",
    "titulares['DATA_INICIO_RELACIONAMENTO_CONTA'] = \"22122008\"\n",
    "titulares['DATA_FIM_RELACIONAMENTO_CONTA'] = \"\"\n",
    "\n",
    "titulares = titulares[['HAD_REPORT', 'OFICIO_NUMBER', 'NUMERO_BANCO', 'NUMERO_AGENCIA', \n",
    "                  'NUMERO_CONTA', 'TIPO_CONTA',\n",
    "                  'TIPO_TITULAR', 'PESSOA_INVESTIGADA', 'TIPO_PESSOA_TITULAR',\n",
    "                  'CPF_CNPJ_TITULAR', 'NOME_TITULAR', 'NOME_DOC_IDENTIFICACAO',\n",
    "                 'NUMERO_DOC_IDENTIFICACAO', 'ENDERECO_LOGRADOURO', 'ENDERECO_CIDADE',\n",
    "                'ENDERECO_UF', 'ENDERECO_PAIS', 'ENDERECO_CEP', 'TELEFONE_PESSOA',\n",
    "                'VALOR_RENDA', 'DATA_ATUALIZACAO_RENDA', 'DATA_INICIO_RELACIONAMENTO_CONTA',\n",
    "                 'DATA_FIM_RELACIONAMENTO_CONTA']].drop_duplicates()\n",
    "titulares_df = pd.DataFrame(titulares)\n",
    "\n",
    "# Correcting 'TITULARES' layout\n",
    "    # NUMERO_BANCO = 3 char\n",
    "    # NUMERO_AGENCIA = 4 char\n",
    "    # NUMERO_CONTA = 20 char\n",
    "    # TIPO_CONTA = 1 char\n",
    "    # TIPO_TITULAR = 1 char\n",
    "    # PESSOA_INVESTIGADA = 1 char\n",
    "    # TIPO_PESSOA_TITULAR = 1 char\n",
    "    # CPF_CNPJ_TITULAR = 14 char\n",
    "    # NOME_TITULAR = 80 char\n",
    "    # NOME_DOC_IDENTIFICACAO = 50 char\n",
    "    # NUMERO_DOC_IDENTIFICACAO = 20 char\n",
    "    # ENDERECO_LOGRADOURO = 80 char\n",
    "    # ENDERECO_CIDADE = 40 char\n",
    "    # ENDERECO_UF = 2 char\n",
    "    # ENDERECO_PAIS = 40 char\n",
    "    # ENDERECO_CEP = 8 char\n",
    "    # TELEFONE_PESSOA = 20 char\n",
    "    # VALOR_RENDA = 14 char\n",
    "    # DATA_ATUALIZACAO_RENDA = 8 char, DDMMYYY\n",
    "    # DATA_INICIO_RELACIONAMENTO_CONTA = 8 char, DDMMYYY\n",
    "    # DATA_FIM_RELACIONAMENTO_CONTA 8 char, DDMMYYY\n",
    "\n",
    "\n",
    "titulares_df['NUMERO_BANCO'] = titulares_df['NUMERO_BANCO'].str.ljust(3, ' ')\n",
    "titulares_df['NUMERO_AGENCIA'] = titulares_df['NUMERO_AGENCIA'].str.ljust(4, ' ')\n",
    "titulares_df['NUMERO_CONTA'] = titulares_df['NUMERO_CONTA'].str.ljust(20, ' ')\n",
    "titulares_df['TIPO_CONTA'] = titulares_df['TIPO_CONTA'].str.ljust(1, ' ')\n",
    "titulares_df['TIPO_TITULAR'] = titulares_df['TIPO_TITULAR'].str.ljust(1, ' ')\n",
    "titulares_df['PESSOA_INVESTIGADA'] = titulares_df['PESSOA_INVESTIGADA'].str.ljust(1, ' ')\n",
    "titulares_df['TIPO_PESSOA_TITULAR'] = titulares_df['TIPO_PESSOA_TITULAR'].str.ljust(1, ' ')\n",
    "titulares_df['CPF_CNPJ_TITULAR'] = titulares_df['CPF_CNPJ_TITULAR'].str.ljust(14, ' ')\n",
    "titulares_df['NOME_TITULAR'] = titulares_df['NOME_TITULAR'].str.ljust(80, ' ')\n",
    "titulares_df['NOME_DOC_IDENTIFICACAO'] = titulares_df['NOME_DOC_IDENTIFICACAO'].str.ljust(50, ' ') \n",
    "titulares_df['NUMERO_DOC_IDENTIFICACAO'] = titulares_df['NUMERO_DOC_IDENTIFICACAO'].str.ljust(20, ' ')\n",
    "titulares_df['ENDERECO_LOGRADOURO'] = titulares_df['ENDERECO_LOGRADOURO'].str.ljust(80, ' ')\n",
    "titulares_df['ENDERECO_CIDADE'] = titulares_df['ENDERECO_CIDADE'].str.ljust(40, ' ')\n",
    "titulares_df['ENDERECO_UF'] = titulares_df['ENDERECO_UF'].str.ljust(2, ' ')\n",
    "titulares_df['ENDERECO_PAIS'] = titulares_df['ENDERECO_PAIS'].str.ljust(40, ' ')\n",
    "titulares_df['ENDERECO_CEP'] = titulares_df['ENDERECO_CEP'].str.ljust(8, ' ')\n",
    "titulares_df['TELEFONE_PESSOA'] = titulares_df['TELEFONE_PESSOA'].str.ljust(20, ' ')\n",
    "titulares_df['VALOR_RENDA'] = titulares_df['VALOR_RENDA'].str.ljust(14, ' ')\n",
    "titulares_df['DATA_ATUALIZACAO_RENDA'] = titulares_df['DATA_ATUALIZACAO_RENDA'].str.ljust(8, ' ') \n",
    "titulares_df['DATA_INICIO_RELACIONAMENTO_CONTA'] = titulares_df['DATA_INICIO_RELACIONAMENTO_CONTA'].str.ljust(8, ' ') \n",
    "titulares_df['DATA_FIM_RELACIONAMENTO_CONTA'] = titulares_df['DATA_FIM_RELACIONAMENTO_CONTA'].str.ljust(8, ' ')\n",
    "# titulares_df['NUMERO_CONTA'].str.len().drop_duplicates() # to check len\n",
    "\n",
    "# Generating archive names + rows\n",
    "column_names = [\"REPORT\", \"NOME_ARQUIVO\", \"LINHA_ARQUIVO\"]\n",
    "titulares_df_txt = pd.DataFrame(columns = column_names)\n",
    "titulares_df_txt['REPORT'] = titulares_df['HAD_REPORT']\n",
    "titulares_df_txt['NOME_ARQUIVO'] = titulares_df['OFICIO_NUMBER']\n",
    "titulares_df_txt['LINHA_ARQUIVO'] = titulares_df[['NUMERO_BANCO', 'NUMERO_AGENCIA', \n",
    "                                                  'NUMERO_CONTA', 'TIPO_CONTA',\n",
    "                                                  'TIPO_TITULAR', 'PESSOA_INVESTIGADA', 'TIPO_PESSOA_TITULAR',\n",
    "                                                  'CPF_CNPJ_TITULAR', 'NOME_TITULAR', 'NOME_DOC_IDENTIFICACAO',\n",
    "                                                  'NUMERO_DOC_IDENTIFICACAO', 'ENDERECO_LOGRADOURO', 'ENDERECO_CIDADE',\n",
    "                                                  'ENDERECO_UF', 'ENDERECO_PAIS', 'ENDERECO_CEP', 'TELEFONE_PESSOA',\n",
    "                                                  'VALOR_RENDA', 'DATA_ATUALIZACAO_RENDA',\n",
    "                                                  'DATA_INICIO_RELACIONAMENTO_CONTA','DATA_FIM_RELACIONAMENTO_CONTA']].apply(lambda x: '\\t'.join(x), axis=1)\n",
    "titulares_df_txt = titulares_df_txt[titulares_df_txt['REPORT'] == \"002\"]\n",
    "titulares_df_csv = titulares_df.merge(oficios_info_df, on='OFICIO_NUMBER', how='left')\n",
    "titulares_df_csv = titulares_df_csv[titulares_df_csv['HAD_REPORT'] == \"002\"]\n",
    "titulares_df_csv = titulares_df_csv.astype({'HAD_REPORT': str,\n",
    "                                          'OFICIO_NUMBER': str,\n",
    "                                          'NUMERO_BANCO': str,\n",
    "                                          'NUMERO_AGENCIA': str,\n",
    "                                          'NUMERO_CONTA': str,\n",
    "                                          'TIPO_CONTA': str,\n",
    "                                          'TIPO_TITULAR': str,\n",
    "                                          'PESSOA_INVESTIGADA': str,\n",
    "                                          'TIPO_PESSOA_TITULAR': str,\n",
    "                                          'CPF_CNPJ_TITULAR': str,\n",
    "                                          'NOME_TITULAR': str,\n",
    "                                          'NOME_DOC_IDENTIFICACAO': str,\n",
    "                                          'NUMERO_DOC_IDENTIFICACAO': str,\n",
    "                                          'ENDERECO_LOGRADOURO': str, \n",
    "                                          'ENDERECO_CIDADE': str,\n",
    "                                          'ENDERECO_UF': str,\n",
    "                                          'ENDERECO_PAIS': str,\n",
    "                                          'ENDERECO_CEP': str,\n",
    "                                          'TELEFONE_PESSOA': str,\n",
    "                                          'VALOR_RENDA': str,\n",
    "                                          'DATA_ATUALIZACAO_RENDA': str,\n",
    "                                          'DATA_INICIO_RELACIONAMENTO_CONTA': str,\n",
    "                                          'DATA_FIM_RELACIONAMENTO_CONTA': str,\n",
    "                                          'CARGO_MAGISTRADO': str,\n",
    "                                          'DATA_OFICIO': str,\n",
    "                                          'EMAIL_CASO': str,\n",
    "                                          'NOME_MAGISTRADO': str,\n",
    "                                          'NOME_TRIBUNAL': str,\n",
    "                                          'NUMERO_PROCESSO': str})\n",
    "print('Job has finished sucessfully', dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating 'TITULARES' .txt\n",
    "for row in titulares_df_txt.groupby('NOME_ARQUIVO'):\n",
    "    row[1]['LINHA_ARQUIVO'].to_csv('/alloc/data/fury_oficios-quebra-sigilo/notebooks/Archives/'+str(row[0]).strip('[]').strip(\"'\")+'_TITULARES.txt', \n",
    "                                      index = False, \n",
    "                                      header = False,\n",
    "                                      quotechar= \"\",\n",
    "                                      sep = \"\\n\",\n",
    "                                      escapechar = '\\\\',\n",
    "                                      quoting=csv.QUOTE_NONE)\n",
    "\n",
    "# Append excel file with sheet = TITULARES to be sent @email.\n",
    "titulares_grouped = titulares_df_csv.groupby('OFICIO_NUMBER')\n",
    "for ti_titles, ti_rows in titulares_grouped:\n",
    "    with pd.ExcelWriter('/alloc/data/fury_oficios-quebra-sigilo/notebooks/Archives/'+str(ti_titles)+'.xlsx',  mode='a') as writer:  \n",
    "        ti_rows.to_excel(writer, sheet_name='TITULARES', index= False, header = True)\n",
    "        \n",
    "print('Job has finished sucessfully', dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting generation of 'EXTRATO' layout\n",
    "extrato = oficios_df[['OFICIO_NUMBER', 'MOV_MOVE_ID', 'BANK_ID', 'WIT_BANK_ACC_BRANCH_ID',\n",
    "                        'WIT_BANK_ACC_NUMBER', 'ACCOUNT_TYPE', 'MOV_AMOUNT_CALC', 'MOV_CREATED_DT_CALC',\n",
    "                         'MOV_DETAIL', 'MOV_TYPE_ID', 'CUS_CUST_DOC_NUMBER', 'PAY_OPERATION_TYPE_ID', \n",
    "                         'HAD_REPORT']].drop_duplicates()\n",
    "extrato = extrato[~extrato['CUS_CUST_DOC_NUMBER'].isna()]\n",
    "extrato['OFICIO_NUMBER'] = extrato['OFICIO_NUMBER']\n",
    "extrato['HAD_REPORT'] = extrato['HAD_REPORT']\n",
    "extrato['CODIGO_CHAVE_EXTRATO'] = extrato['MOV_MOVE_ID'].fillna('0').astype({'MOV_MOVE_ID': int}).astype(str)\n",
    "#extrato['NUMERO_BANCO'] = extrato['BANK_ID'].fillna('033')\n",
    "extrato['NUMERO_BANCO'] = \"323\"\n",
    "#extrato['NUMERO_AGENCIA'] = extrato['WIT_BANK_ACC_BRANCH_ID'].fillna('2167')\n",
    "extrato['NUMERO_AGENCIA'] = \"0001\"\n",
    "#extrato['NUMERO_CONTA'] = extrato['WIT_BANK_ACC_NUMBER'].fillna('130010391')\n",
    "extrato['NUMERO_CONTA'] = \"10573521\"\n",
    "# extrato['TIPO_CONTA'] = np.where(extrato['NUMERO_BANCO'] == \"323\", '4',\n",
    "#                    np.where(extrato['ACCOUNT_TYPE'] == \"checking_account\", '1',\n",
    "#                    np.where(extrato['ACCOUNT_TYPE'] == \"savings_account\", '2', '4')))\n",
    "extrato['TIPO_CONTA'] = \"4\"\n",
    "extrato['DATA_LANCAMENTO'] = extrato['MOV_CREATED_DT_CALC'].fillna('')\n",
    "extrato['NUMERO_DOCUMENTO'] = \"\"\n",
    "extrato['DESCRICAO_LANCAMENTO'] = np.where((extrato['MOV_DETAIL'] == \"money_transfer\") & (extrato['MOV_TYPE_ID'] == 'expense'), 'Envio de dinheiro entre contas Mercado Pago', \n",
    "                                  np.where((extrato['MOV_DETAIL'] == \"withdraw\") & (extrato['MOV_TYPE_ID'] == 'expense'), 'Envio de TED/DOC interbancaria', \n",
    "                                  np.where((extrato['MOV_DETAIL'] == \"money_transfer\") & (extrato['MOV_TYPE_ID'] == 'income'), 'Recebimento de dinheiro entre contas Mercado Pago', \n",
    "                                  np.where((extrato['MOV_DETAIL'] == \"payment\") & (extrato['MOV_TYPE_ID'] == 'income'), 'Recebimento de dinheiro entre contas Mercado Pago', \n",
    "                                  np.where((extrato['MOV_DETAIL'] == \"payment\") & (extrato['MOV_TYPE_ID'] == 'expense'), 'Pagamento de dinheiro entre contas Mercado Pago', \n",
    "                                  np.where((extrato['MOV_DETAIL'] == \"payment\") & (extrato['MOV_TYPE_ID'] == 'fund'), 'Recebimento de dinheiro entre contas Mercado Pago', \n",
    "                                  np.where((extrato['MOV_DETAIL'] == \"account_fund\") & (extrato['MOV_TYPE_ID'] == 'fund'), 'Recebimento de dinheiro entre contas Mercado Pago', \n",
    "                                  np.where((extrato['MOV_DETAIL'] == \"cellphone_recharge\") & (extrato['MOV_TYPE_ID'] == 'expense'), 'Pagamento de despesas entre contas Mercado Pago', \n",
    "                                   ''))))))))\n",
    "extrato['TIPO_LANCAMENTO'] = np.where((extrato['MOV_DETAIL'] == \"money_transfer\") & (extrato['MOV_TYPE_ID'] == 'expense'), '117', \n",
    "                             np.where((extrato['MOV_DETAIL'] == \"withdraw\") & (extrato['MOV_TYPE_ID'] == 'expense'), '120', \n",
    "                             np.where((extrato['MOV_DETAIL'] == \"money_transfer\") & (extrato['MOV_TYPE_ID'] == 'income'), '213', \n",
    "                             np.where((extrato['MOV_DETAIL'] == \"payment\") & (extrato['MOV_TYPE_ID'] == 'income'), '218', \n",
    "                             np.where((extrato['MOV_DETAIL'] == \"payment\") & (extrato['MOV_TYPE_ID'] == 'expense'), '117', \n",
    "                             np.where((extrato['MOV_DETAIL'] == \"payment\") & (extrato['MOV_TYPE_ID'] == 'fund'), '217', \n",
    "                             np.where((extrato['MOV_DETAIL'] == \"account_fund\") & (extrato['MOV_TYPE_ID'] == 'fund'), '217', \n",
    "                             np.where((extrato['MOV_DETAIL'] == \"cellphone_recharge\") & (extrato['MOV_TYPE_ID'] == 'expense'), '117', \n",
    "                                ''))))))))\n",
    "extrato['VALOR_LANCAMENTO'] = extrato['MOV_AMOUNT_CALC'].fillna('')\n",
    "extrato['NATUREZA_LANCAMENTO'] = np.where((extrato['MOV_DETAIL'] == \"money_transfer\") & (extrato['MOV_TYPE_ID'] == 'expense'), 'D', \n",
    "                                 np.where((extrato['MOV_DETAIL'] == \"withdraw\") & (extrato['MOV_TYPE_ID'] == 'expense'), 'D', \n",
    "                                 np.where((extrato['MOV_DETAIL'] == \"money_transfer\") & (extrato['MOV_TYPE_ID'] == 'income'), 'C', \n",
    "                                 np.where((extrato['MOV_DETAIL'] == \"payment\") & (extrato['MOV_TYPE_ID'] == 'income'), 'C', \n",
    "                                 np.where((extrato['MOV_DETAIL'] == \"payment\") & (extrato['MOV_TYPE_ID'] == 'expense'), 'D', \n",
    "                                 np.where((extrato['MOV_DETAIL'] == \"payment\") & (extrato['MOV_TYPE_ID'] == 'fund'), 'C', \n",
    "                                 np.where((extrato['MOV_DETAIL'] == \"account_fund\") & (extrato['MOV_TYPE_ID'] == 'fund'), 'C', \n",
    "                                 np.where((extrato['MOV_DETAIL'] == \"cellphone_recharge\") & (extrato['MOV_TYPE_ID'] == 'expense'), 'D', \n",
    "                                 ''))))))))\n",
    "extrato['VALOR_SALDO'] = \"\"\n",
    "extrato['NATUREZA_SALDO'] = extrato['NATUREZA_LANCAMENTO'].fillna('')\n",
    "extrato['LOCAL_TRANSACAO'] = \"Internet\"\n",
    "\n",
    "extrato = extrato[['HAD_REPORT', 'OFICIO_NUMBER', 'CODIGO_CHAVE_EXTRATO', 'NUMERO_BANCO', 'NUMERO_AGENCIA', \n",
    "                  'NUMERO_CONTA', 'TIPO_CONTA', 'DATA_LANCAMENTO', 'NUMERO_DOCUMENTO',\n",
    "                  'DESCRICAO_LANCAMENTO', 'TIPO_LANCAMENTO', 'VALOR_LANCAMENTO',\n",
    "                  'NATUREZA_LANCAMENTO', 'VALOR_SALDO', 'NATUREZA_SALDO', 'LOCAL_TRANSACAO']].drop_duplicates()\n",
    "extrato_df = pd.DataFrame(extrato)\n",
    "\n",
    "# Correcting 'EXTRATO' layout\n",
    "    # CODIGO_CHAVE_EXTRATO = 18 char\n",
    "    # NUMERO_BANCO = 3 char\n",
    "    # NUMERO_AGENCIA = 4 char\n",
    "    # NUMERO_CONTA = 20 char\n",
    "    # TIPO_CONTA = 1 char\n",
    "    # DATA_LANCAMENTO = 8 char, DDMMYYYY\n",
    "    # NUMERO_DOCUMENTO = 20 char\n",
    "    # DESCRICAO_LANCAMENTO = 50 char\n",
    "    # TIPO_LANCAMENTO = 3 char\n",
    "    # VALOR_LANCAMENTO = 14 char\n",
    "    # NATUREZA_LANCAMENTO = 1 char\n",
    "    # NATUREZA_SALDO = 1 char\n",
    "    # LOCAL_TRANSACAO = 80 char\n",
    "    \n",
    "extrato_df['CODIGO_CHAVE_EXTRATO'] = extrato_df['CODIGO_CHAVE_EXTRATO'].str.ljust(18, ' ')\n",
    "extrato_df['NUMERO_BANCO'] = extrato_df['NUMERO_BANCO'].str.ljust(3, ' ')\n",
    "extrato_df['NUMERO_AGENCIA'] = extrato_df['NUMERO_AGENCIA'].str.ljust(4, ' ')\n",
    "extrato_df['NUMERO_CONTA'] = extrato_df['NUMERO_CONTA'].str.ljust(20, ' ')\n",
    "extrato_df['TIPO_CONTA'] = extrato_df['TIPO_CONTA'].str.ljust(1, ' ')\n",
    "extrato_df['DATA_LANCAMENTO'] = extrato_df['DATA_LANCAMENTO'].str.ljust(8, ' ')\n",
    "extrato_df['NUMERO_DOCUMENTO'] = extrato_df['NUMERO_DOCUMENTO'].str.ljust(20, '0')\n",
    "extrato_df['DESCRICAO_LANCAMENTO'] = extrato_df['DESCRICAO_LANCAMENTO'].str.ljust(50, ' ')\n",
    "extrato_df['TIPO_LANCAMENTO'] = extrato_df['TIPO_LANCAMENTO'].str.ljust(3, ' ')\n",
    "extrato_df['VALOR_LANCAMENTO'] = extrato_df['VALOR_LANCAMENTO'].str.ljust(14, ' ')\n",
    "extrato_df['NATUREZA_LANCAMENTO'] = extrato_df['NATUREZA_LANCAMENTO'].str.ljust(1, ' ')\n",
    "extrato_df['VALOR_SALDO'] = extrato_df['VALOR_SALDO'].str.ljust(14, '0')\n",
    "extrato_df['NATUREZA_SALDO'] = extrato_df['NATUREZA_SALDO'].str.ljust(1, ' ')\n",
    "extrato_df['LOCAL_TRANSACAO'] = extrato_df['LOCAL_TRANSACAO'].str.ljust(1, ' ')\n",
    "# extrato_df['NUMERO_CONTA'].str.len().drop_duplicates() # to check len\n",
    "\n",
    "\n",
    "# Generating archive names + rows\n",
    "column_names = [\"REPORT\", \"NOME_ARQUIVO\", \"LINHA_ARQUIVO\"]\n",
    "extrato_df_txt = pd.DataFrame(columns = column_names)\n",
    "extrato_df_txt['REPORT'] = extrato_df['HAD_REPORT']\n",
    "extrato_df_txt['NOME_ARQUIVO'] = extrato_df['OFICIO_NUMBER']\n",
    "extrato_df_txt['LINHA_ARQUIVO'] = extrato_df[['CODIGO_CHAVE_EXTRATO', 'NUMERO_BANCO', 'NUMERO_AGENCIA', \n",
    "                                      'NUMERO_CONTA', 'TIPO_CONTA', 'DATA_LANCAMENTO', 'NUMERO_DOCUMENTO',\n",
    "                                       'DESCRICAO_LANCAMENTO', 'TIPO_LANCAMENTO', 'VALOR_LANCAMENTO',\n",
    "                                      'NATUREZA_LANCAMENTO', 'VALOR_SALDO', 'NATUREZA_SALDO', 'LOCAL_TRANSACAO']].apply(lambda x: '\\t'.join(x), axis=1)\n",
    "extrato_df_txt = extrato_df_txt[extrato_df_txt['REPORT'] == \"002\"]\n",
    "extrato_df_csv = extrato_df.merge(oficios_info_df, on='OFICIO_NUMBER', how='left')\n",
    "extrato_df_csv = extrato_df_csv[extrato_df_csv['HAD_REPORT'] == \"002\"]\n",
    "extrato_df_csv = extrato_df_csv.astype({'HAD_REPORT': str,\n",
    "                                          'OFICIO_NUMBER': str,\n",
    "                                          'CODIGO_CHAVE_EXTRATO': str,\n",
    "                                          'NUMERO_BANCO': str,\n",
    "                                          'NUMERO_AGENCIA': str, \n",
    "                                          'NUMERO_CONTA': str,\n",
    "                                          'TIPO_CONTA': str,\n",
    "                                          'DATA_LANCAMENTO': str,\n",
    "                                          'NUMERO_DOCUMENTO': str, \n",
    "                                          'DESCRICAO_LANCAMENTO': str, \n",
    "                                          'TIPO_LANCAMENTO': str,\n",
    "                                          'VALOR_LANCAMENTO': str,\n",
    "                                          'NATUREZA_LANCAMENTO': str, \n",
    "                                          'VALOR_SALDO': str,\n",
    "                                          'NATUREZA_SALDO': str,\n",
    "                                          'LOCAL_TRANSACAO': str,\n",
    "                                          'CARGO_MAGISTRADO': str,\n",
    "                                          'DATA_OFICIO': str, \n",
    "                                          'EMAIL_CASO': str,\n",
    "                                          'NOME_MAGISTRADO': str,\n",
    "                                          'NOME_TRIBUNAL': str, \n",
    "                                          'NUMERO_PROCESSO': str})\n",
    "print('Job has finished sucessfully', dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating 'EXTRATO' .txt\n",
    "#extrato_df_txt_002 = extrato_df_txt[extrato_df_txt['REPORT'] == \"002\"]\n",
    "for row in extrato_df_txt.groupby('NOME_ARQUIVO'):\n",
    "    row[1]['LINHA_ARQUIVO'].to_csv('/alloc/data/fury_oficios-quebra-sigilo/notebooks/Archives/'+str(row[0]).strip('[]').strip(\"'\")+'_EXTRATO.txt', \n",
    "                                      index = False, \n",
    "                                      header = False,\n",
    "                                      quotechar= \"\",\n",
    "                                      sep = \"\\n\",\n",
    "                                      escapechar = '\\\\',\n",
    "                                      quoting=csv.QUOTE_NONE)\n",
    "    \n",
    "# Append excel file with sheet = EXTRATO to be sent @email.\n",
    "extrato_grouped = extrato_df_csv.groupby('OFICIO_NUMBER')\n",
    "for ex_titles, ex_rows in extrato_grouped:\n",
    "    with pd.ExcelWriter('/alloc/data/fury_oficios-quebra-sigilo/notebooks/Archives/'+str(ex_titles)+'.xlsx',  mode='a') as writer:  \n",
    "        ex_rows.to_excel(writer, sheet_name='EXTRATO', index= False, header = True)\n",
    "        \n",
    "print('Job has finished sucessfully', dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting generation of 'ORIGEM DESTINO' layout\n",
    "od = oficios_df[['OFICIO_NUMBER', 'MOV_MOVE_ID', 'BANK_ID', 'WIT_BANK_ACC_BRANCH_ID', 'PAY_REASON_ID',\n",
    "                        'WIT_BANK_ACC_NUMBER', 'ACCOUNT_TYPE', 'MOV_AMOUNT_CALC', 'CUS_CUST_DOC_NUMBER_SEL', 'MOV_CREATED_DT_CALC',\n",
    "                         'MOV_DETAIL', 'MOV_TYPE_ID', 'PAY_OPERATION_TYPE_ID', 'CUS_FULL_NAME_SEL', 'CUS_CUST_DOC_TYPE_SEL',\n",
    "                         'HAD_REPORT']].drop_duplicates()\n",
    "#od = od[~od['CUS_CUST_DOC_NUMBER'].isna()]\n",
    "od['OFICIO_NUMBER'] = od['OFICIO_NUMBER']\n",
    "od['HAD_REPORT'] = od['HAD_REPORT']\n",
    "od['CODIGO_CHAVE_OD'] = np.arange(len(od))+1\n",
    "od['CODIGO_CHAVE_OD'] = od['CODIGO_CHAVE_OD'].astype(str)\n",
    "od['CODIGO_CHAVE_EXTRATO'] = od['MOV_MOVE_ID'].fillna('0').astype({'MOV_MOVE_ID': int}).astype(str)\n",
    "od['VALOR_TRANSACAO'] = od['MOV_AMOUNT_CALC'].fillna('')\n",
    "od['NUMERO_DOCUMENTO_TRANSACAO'] = \"\"\n",
    "od['NUMERO_BANCO_OD'] = od['BANK_ID'].fillna('323')\n",
    "od['NUMERO_AGENCIA_OD'] = od['WIT_BANK_ACC_BRANCH_ID'].fillna('0001')\n",
    "od['NUMERO_CONTA_OD'] = od['WIT_BANK_ACC_NUMBER'].fillna('10573521')\n",
    "od['TIPO_CONTA_OD'] = np.where(od['NUMERO_BANCO_OD'] == \"323\", '4',\n",
    "                    np.where(od['ACCOUNT_TYPE'] == \"checking_account\", '1',\n",
    "                    np.where(od['ACCOUNT_TYPE'] == \"savings_account\", '2', '4')))\n",
    "#od['TIPO_PESSOA_OD'] = np.where(od['CUS_CUST_DOC_TYPE_SEL'] == \"CPF\", \"1\", \"2\")\n",
    "od['TIPO_PESSOA_OD'] = np.where(od['CUS_CUST_DOC_TYPE_SEL'].isna(), \n",
    "                        np.where(od['CUS_CUST_DOC_NUMBER_SEL'].fillna('').apply(len) == 11, '1', '2')\n",
    "                                 ,np.where(od['CUS_CUST_DOC_TYPE_SEL'] == \"CPF\", \"1\", \"2\"))\n",
    "od['CPF_CNPJ_OD'] = od['CUS_CUST_DOC_NUMBER_SEL'].fillna('')\n",
    "od['NOME_PESSOA_OD'] = od['CUS_FULL_NAME_SEL'].fillna('')\n",
    "od['NOME_DOC_IDENTIFICACAO_OD'] = \"\"\n",
    "od['NUMERO_DOC_IDENTIFICACAO_OD'] = \"\"\n",
    "od['CODIGO_DE_BARRAS'] = \"\"\n",
    "od['NOME_ENDOSSANTE_CHEQUE'] = \"\"\n",
    "od['DOC_ENDOSSANTE_CHEQUE'] = \"\"\n",
    "od['SITUACAO_IDENTIFICACAO'] = \"0\"\n",
    "od['OBSERVACAO'] = od['PAY_REASON_ID'].fillna('')\n",
    "\n",
    "\n",
    "\n",
    "od = od[['HAD_REPORT', 'OFICIO_NUMBER', 'CODIGO_CHAVE_OD', 'CODIGO_CHAVE_EXTRATO',\n",
    "        'VALOR_TRANSACAO', 'NUMERO_DOCUMENTO_TRANSACAO', 'NUMERO_BANCO_OD',\n",
    "        'NUMERO_AGENCIA_OD', 'NUMERO_CONTA_OD', 'TIPO_CONTA_OD',\n",
    "        'TIPO_PESSOA_OD', 'CPF_CNPJ_OD', 'NOME_PESSOA_OD',\n",
    "        'NOME_DOC_IDENTIFICACAO_OD', 'NUMERO_DOC_IDENTIFICACAO_OD', 'CODIGO_DE_BARRAS', 'NOME_ENDOSSANTE_CHEQUE',\n",
    "        'DOC_ENDOSSANTE_CHEQUE', 'SITUACAO_IDENTIFICACAO', 'OBSERVACAO']].drop_duplicates()\n",
    "od_df = pd.DataFrame(od)\n",
    "\n",
    "# Correcting 'ORIGEM DESTINO' layout\n",
    "    # CODIGO_CHAVE_OD = 18 char\n",
    "    # CODIGO_CHAVE_EXTRATO = 18 char\n",
    "    # VALOR_TRANSACAO = 14 char\n",
    "    # NUMERO_DOCUMENTO_TRANSACAO = 20 char\n",
    "    # NUMERO_BANCO_OD = 3 char\n",
    "    # NUMERO_AGENCIA_OD = 4 char\n",
    "    # NUMERO_CONTA_OD = 20 char\n",
    "    # TIPO_CONTA_OD = 1 char\n",
    "    # TIPO_PESSOA_OD = 1 char\n",
    "    # CPF_CNPJ_OD = 14 char\n",
    "    # NOME_PESSOA_OD = 80 char\n",
    "    # NOME_DOC_IDENTIFICACAO_OD = 20 char\n",
    "    # NUMERO_DOC_IDENTIFICACAO_OD = 20 char\n",
    "    # CODIGO_DE_BARRAS = 100 char\n",
    "    # NOME_ENDOSSANTE_CHEQUE = 80 char\n",
    "    # DOC_ENDOSSANTE_CHEQUE = 50 char\n",
    "    # SITUACAO_IDENTIFICACAO = 1 char\n",
    "    # OBSERVACAO = 250 char\n",
    "    \n",
    "od_df['CODIGO_CHAVE_OD'] = od_df['CODIGO_CHAVE_OD'].str.ljust(18, ' ')\n",
    "od_df['CODIGO_CHAVE_EXTRATO'] = od_df['CODIGO_CHAVE_EXTRATO'].str.ljust(18, ' ')\n",
    "od_df['VALOR_TRANSACAO'] = od_df['VALOR_TRANSACAO'].str.ljust(14, ' ')\n",
    "od_df['NUMERO_DOCUMENTO_TRANSACAO'] = od_df['NUMERO_DOCUMENTO_TRANSACAO'].str.ljust(20, ' ')\n",
    "od_df['NUMERO_BANCO_OD'] = od_df['NUMERO_BANCO_OD'].str.ljust(3, ' ')\n",
    "od_df['NUMERO_AGENCIA_OD'] = od_df['NUMERO_AGENCIA_OD'].str.ljust(4, ' ')\n",
    "od_df['NUMERO_CONTA_OD'] = od_df['NUMERO_CONTA_OD'].str.ljust(20, ' ')\n",
    "od_df['TIPO_CONTA_OD'] = od_df['TIPO_CONTA_OD'].str.ljust(1, ' ')\n",
    "od_df['TIPO_PESSOA_OD'] = od_df['TIPO_PESSOA_OD'].str.ljust(1, ' ')\n",
    "od_df['CPF_CNPJ_OD'] = od_df['CPF_CNPJ_OD'].str.ljust(14, ' ')\n",
    "od_df['NOME_PESSOA_OD'] = od_df['NOME_PESSOA_OD'].str.ljust(14, ' ')\n",
    "od_df['NOME_DOC_IDENTIFICACAO_OD'] = od_df['NOME_DOC_IDENTIFICACAO_OD'].str.ljust(20, ' ')\n",
    "od_df['NUMERO_DOC_IDENTIFICACAO_OD'] = od_df['NUMERO_DOC_IDENTIFICACAO_OD'].str.ljust(20, ' ')\n",
    "od_df['CODIGO_DE_BARRAS'] = od_df['CODIGO_DE_BARRAS'].str.ljust(100, ' ')\n",
    "od_df['NOME_ENDOSSANTE_CHEQUE'] = od_df['NOME_ENDOSSANTE_CHEQUE'].str.ljust(80, ' ')\n",
    "od_df['DOC_ENDOSSANTE_CHEQUE'] = od_df['DOC_ENDOSSANTE_CHEQUE'].str.ljust(50, ' ')\n",
    "od_df['SITUACAO_IDENTIFICACAO'] = od_df['SITUACAO_IDENTIFICACAO'].str.ljust(1, ' ')\n",
    "od_df['OBSERVACAO'] = od['OBSERVACAO'].str.ljust(250, ' ')\n",
    "# od_df['OBSERVACAO'].str.len().drop_duplicates() # to check len\n",
    "\n",
    "\n",
    "\n",
    "# Generating archive names + rows\n",
    "column_names = [\"REPORT\", \"NOME_ARQUIVO\", \"LINHA_ARQUIVO\"]\n",
    "od_df_txt = pd.DataFrame(columns = column_names)\n",
    "od_df_txt['REPORT'] = od_df['HAD_REPORT']\n",
    "od_df_txt['NOME_ARQUIVO'] = od_df['OFICIO_NUMBER']\n",
    "od_df_txt['LINHA_ARQUIVO'] = od_df[['CODIGO_CHAVE_OD', 'CODIGO_CHAVE_EXTRATO',\n",
    "        'VALOR_TRANSACAO', 'NUMERO_DOCUMENTO_TRANSACAO', 'NUMERO_BANCO_OD',\n",
    "        'NUMERO_AGENCIA_OD', 'NUMERO_CONTA_OD', 'TIPO_CONTA_OD',\n",
    "        'TIPO_PESSOA_OD', 'CPF_CNPJ_OD', 'NOME_PESSOA_OD',\n",
    "        'NOME_DOC_IDENTIFICACAO_OD', 'NUMERO_DOC_IDENTIFICACAO_OD', 'CODIGO_DE_BARRAS', 'NOME_ENDOSSANTE_CHEQUE',\n",
    "        'DOC_ENDOSSANTE_CHEQUE', 'SITUACAO_IDENTIFICACAO', 'OBSERVACAO']].apply(lambda x: '\\t'.join(x), axis=1)\n",
    "od_df_txt = od_df_txt[od_df_txt['REPORT'] == \"002\"]\n",
    "od_df_csv = od_df.merge(oficios_info_df, on='OFICIO_NUMBER', how='left')\n",
    "od_df_csv = od_df_csv[od_df_csv['HAD_REPORT'] == \"002\"]\n",
    "od_df_csv = od_df_csv.astype({'HAD_REPORT': str,\n",
    "                              'OFICIO_NUMBER': str,\n",
    "                              'CODIGO_CHAVE_OD': str,\n",
    "                              'CODIGO_CHAVE_EXTRATO': str,\n",
    "                              'VALOR_TRANSACAO': str,\n",
    "                              'NUMERO_DOCUMENTO_TRANSACAO': str,\n",
    "                              'NUMERO_BANCO_OD': str,\n",
    "                              'NUMERO_AGENCIA_OD': str,\n",
    "                              'NUMERO_CONTA_OD': str,\n",
    "                              'TIPO_CONTA_OD': str,\n",
    "                              'TIPO_PESSOA_OD': str,\n",
    "                              'CPF_CNPJ_OD': str,\n",
    "                              'NOME_PESSOA_OD': str,\n",
    "                              'NOME_DOC_IDENTIFICACAO_OD': str,\n",
    "                              'NUMERO_DOC_IDENTIFICACAO_OD': str,\n",
    "                              'CODIGO_DE_BARRAS': str,\n",
    "                              'NOME_ENDOSSANTE_CHEQUE': str,\n",
    "                              'DOC_ENDOSSANTE_CHEQUE': str,\n",
    "                              'SITUACAO_IDENTIFICACAO': str,\n",
    "                              'OBSERVACAO': str,\n",
    "                              'CARGO_MAGISTRADO': str,\n",
    "                              'DATA_OFICIO': str,\n",
    "                              'EMAIL_CASO': str,\n",
    "                              'NOME_MAGISTRADO': str,\n",
    "                              'NOME_TRIBUNAL': str,\n",
    "                              'NUMERO_PROCESSO': str})\n",
    "print('Job has finished sucessfully', dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating 'ORIGEM DESTINO' .txt\n",
    "#od_df_txt_002 = od_df_txt[od_df_txt['REPORT'] == \"002\"]\n",
    "for row in od_df_txt.groupby('NOME_ARQUIVO'):\n",
    "    row[1]['LINHA_ARQUIVO'].to_csv('/alloc/data/fury_oficios-quebra-sigilo/notebooks/Archives/'+str(row[0]).strip('[]').strip(\"'\")+'_ORIGEM_DESTINO.txt', \n",
    "                                      index = False, \n",
    "                                      header = False,\n",
    "                                      quotechar= \"\",\n",
    "                                      sep = \"\\n\",\n",
    "                                      escapechar = '\\\\',\n",
    "                                      quoting=csv.QUOTE_NONE)\n",
    "\n",
    "# Append excel file with sheet = ORIGEM_DESTINO to be sent @email.\n",
    "od_grouped = od_df_csv.groupby('OFICIO_NUMBER')\n",
    "for od_titles, od_rows in od_grouped:\n",
    "    with pd.ExcelWriter('/alloc/data/fury_oficios-quebra-sigilo/notebooks/Archives/'+str(od_titles)+'.xlsx',  mode='a') as writer:  \n",
    "        od_rows.to_excel(writer, sheet_name='ORIGEM_DESTINO', index= False, header = True)\n",
    "        \n",
    "print('Job has finished sucessfully', dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting generation of 'INVESTIGADOS' layout\n",
    "inv = oficios_df[['OFICIO_NUMBER', 'MOV_MOVE_ID', 'BANK_ID', 'WIT_BANK_ACC_BRANCH_ID',\n",
    "                        'WIT_BANK_ACC_NUMBER', 'ACCOUNT_TYPE', 'MOV_AMOUNT_CALC', 'MOV_CREATED_DT_CALC',\n",
    "                         'MOV_DETAIL', 'MOV_TYPE_ID', 'PAY_OPERATION_TYPE_ID', \n",
    "                         'CUS_CUST_DOC_NUMBER', 'CUS_CUST_DOC_TYPE', 'CUS_FULL_NAME',\n",
    "                         'HAD_REPORT']].drop_duplicates()\n",
    "#inv = inv[~inv['CUS_CUST_DOC_NUMBER_BUY'].isna()]\n",
    "\n",
    "cus_full_name = inv[['CUS_FULL_NAME']].groupby(inv['CUS_CUST_DOC_NUMBER']).nth(0).reset_index()\n",
    "cus_full_name['CUS_FULL_NAME_CORRECTED'] = cus_full_name['CUS_FULL_NAME']\n",
    "del cus_full_name['CUS_FULL_NAME']\n",
    "inv = inv.merge(doc_info_df, on=['OFICIO_NUMBER', 'CUS_CUST_DOC_NUMBER'], how='left')\n",
    "inv = inv.merge(cus_full_name, on=['CUS_CUST_DOC_NUMBER'], how = 'left')\n",
    "inv['OFICIO_NUMBER'] = inv['OFICIO_NUMBER']\n",
    "inv['HAD_REPORT'] = inv['HAD_REPORT']\n",
    "inv['TIPO_PESSOA_OD'] = np.where(inv['CUS_CUST_DOC_TYPE'].isna(), \n",
    "                        np.where(inv['CUS_CUST_DOC_NUMBER'].apply(len) == 11, '1', '2')\n",
    "                                 ,np.where(inv['CUS_CUST_DOC_TYPE'] == \"CPF\", \"1\", \"2\"))\n",
    "inv['CPF_CNPJ_OD'] = inv['CUS_CUST_DOC_NUMBER'].fillna('Nome não encontrado')\n",
    "inv['NOME_PESSOA_OD'] = inv['CUS_FULL_NAME_CORRECTED'].fillna('Nome não encontrado')\n",
    "inv['POSSUI_RELACIONAMENTO'] = np.where(inv['HAD_REPORT'] == \"002\", \"1\", \"0\")\n",
    "inv['POSSUI_CONTA'] = np.where(inv['HAD_REPORT'] == \"002\", \"1\", \"0\")\n",
    "inv['POSSUI_BDV'] = np.where(inv['HAD_REPORT'] == \"002\", \"1\", \"0\")\n",
    "inv['OBSERVACAO'] = \"\"\n",
    "inv['DATA_INICIO_AFASTAMENTO'] = inv['RANGE_MIN_CALC']\n",
    "inv['DATA_FIM_AFASTAMENTO'] = inv['RANGE_MAX_CALC']\n",
    "\n",
    "\n",
    "inv = inv[['HAD_REPORT', 'OFICIO_NUMBER', 'TIPO_PESSOA_OD', \n",
    "          'CPF_CNPJ_OD', 'NOME_PESSOA_OD', 'POSSUI_RELACIONAMENTO', 'POSSUI_CONTA', 'POSSUI_BDV',\n",
    "          'OBSERVACAO', 'DATA_INICIO_AFASTAMENTO', 'DATA_FIM_AFASTAMENTO']].drop_duplicates()\n",
    "inv_df = pd.DataFrame(inv)\n",
    "\n",
    "# Correcting 'INVESTIGADOS' layout\n",
    "    # TIPO_PESSOA_OD = 1 char\n",
    "    # CPF_CNPJ_OD = 14 char\n",
    "    # NOME_PESSOA_OD = 80 char\n",
    "    # POSSUI_RELACIONAMENTO = 1 char\n",
    "    # POSSUI_CONTA = 1 char\n",
    "    # POSSUI_BDV = 1 char\n",
    "    # OBSERVACAO = 250 char\n",
    "    # DATA_INICIO_AFASTAMENTO = 8 char, DDMMYYYY\n",
    "    # DATA_FIM_AFASTAMENTO = 8 char, DDMMYYYY\n",
    "    \n",
    "\n",
    "    \n",
    "inv_df['TIPO_PESSOA_OD'] = inv_df['TIPO_PESSOA_OD'].str.ljust(1, ' ')\n",
    "inv_df['CPF_CNPJ_OD'] = inv_df['CPF_CNPJ_OD'].str.ljust(14, ' ')\n",
    "inv_df['NOME_PESSOA_OD'] = inv_df['NOME_PESSOA_OD'].str.ljust(80, ' ')\n",
    "inv_df['POSSUI_RELACIONAMENTO'] = inv_df['POSSUI_RELACIONAMENTO'].str.ljust(1, ' ')\n",
    "inv_df['POSSUI_CONTA'] = inv_df['POSSUI_CONTA'].str.ljust(1, ' ')\n",
    "inv_df['POSSUI_BDV'] = inv_df['POSSUI_BDV'].str.ljust(1, ' ')\n",
    "inv_df['OBSERVACAO'] = inv_df['OBSERVACAO'].str.ljust(250, ' ')\n",
    "inv_df['DATA_INICIO_AFASTAMENTO'] = inv_df['DATA_INICIO_AFASTAMENTO'].str.ljust(8, ' ')\n",
    "inv_df['DATA_FIM_AFASTAMENTO'] = inv_df['DATA_FIM_AFASTAMENTO'].str.ljust(8, ' ')\n",
    "# inv_df['OBSERVACAO'].str.len().drop_duplicates() # to check len\n",
    "\n",
    "\n",
    "# Generating archive names + rows\n",
    "column_names = [\"REPORT\", \"NOME_ARQUIVO\", \"LINHA_ARQUIVO\"]\n",
    "inv_df_txt = pd.DataFrame(columns = column_names)\n",
    "inv_df_txt['REPORT'] = inv_df['HAD_REPORT']\n",
    "inv_df_txt['NOME_ARQUIVO'] = inv_df['OFICIO_NUMBER']\n",
    "inv_df_txt['LINHA_ARQUIVO'] = inv_df[['TIPO_PESSOA_OD', 'CPF_CNPJ_OD', 'NOME_PESSOA_OD',\n",
    "                                      'POSSUI_RELACIONAMENTO', 'POSSUI_CONTA', 'POSSUI_BDV', 'OBSERVACAO',\n",
    "                                      'DATA_INICIO_AFASTAMENTO', 'DATA_FIM_AFASTAMENTO']].apply(lambda x: '\\t'.join(x), axis=1)\n",
    "inv_df_txt = inv_df_txt[inv_df_txt['REPORT'] == \"002\"]\n",
    "inv_df_csv = inv_df.merge(oficios_info_df, on='OFICIO_NUMBER', how='left')\n",
    "inv_df_csv = inv_df_csv[inv_df_csv['HAD_REPORT'] == \"002\"]\n",
    "inv_df_csv = inv_df_csv.astype({'HAD_REPORT': str,\n",
    "                              'OFICIO_NUMBER': str,\n",
    "                              'TIPO_PESSOA_OD': str,\n",
    "                              'CPF_CNPJ_OD': str,\n",
    "                              'NOME_PESSOA_OD': str,\n",
    "                              'POSSUI_RELACIONAMENTO': str,\n",
    "                              'POSSUI_CONTA': str,\n",
    "                              'POSSUI_BDV': str,\n",
    "                              'OBSERVACAO': str,\n",
    "                              'DATA_INICIO_AFASTAMENTO': str,\n",
    "                              'DATA_FIM_AFASTAMENTO': str})\n",
    "print('Job has finished sucessfully', dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating 'INVESTIGADOS' .txt\n",
    "for row in inv_df_txt.groupby('NOME_ARQUIVO'):\n",
    "    row[1]['LINHA_ARQUIVO'].to_csv('/alloc/data/fury_oficios-quebra-sigilo/notebooks/Archives/'+str(row[0]).strip('[]').strip(\"'\")+'_INVESTIGADO.txt', \n",
    "                                      index = False, \n",
    "                                      header = False,\n",
    "                                      quotechar= \"\",\n",
    "                                      sep = \"\\n\",\n",
    "                                      escapechar = '\\\\',\n",
    "                                      quoting=csv.QUOTE_NONE)\n",
    "\n",
    "# Append excel file with sheet = INVESTIGADO to be sent @email.\n",
    "inv_grouped = inv_df_csv.groupby('OFICIO_NUMBER')\n",
    "for inv_titles, inv_rows in inv_grouped:\n",
    "    with pd.ExcelWriter('/alloc/data/fury_oficios-quebra-sigilo/notebooks/Archives/'+str(inv_titles)+'.xlsx',  mode='a') as writer:  \n",
    "        inv_rows.to_excel(writer, sheet_name='INVESTIGADO', index= False, header = True)\n",
    "        \n",
    "print('Job has finished sucessfully', dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#of = [\"059-PCRO-000028-45\"]\n",
    "#oficios_email = oficios_info_df[~oficios_info_df.OFICIO_NUMBER.isin(of)]\n",
    "#oficios_email = oficios_info_df[oficios_info_df.OFICIO_NUMBER.isin(of)]\n",
    "oficios_email = oficios_info_df\n",
    "# oficios_email['EMAIL_CASO_sCALC'] = np.where(oficios_email['EMAIL_CASO'] == '04vara.pa@trfl.jus.br',\n",
    "#                                              'raphael.dayan@mercadopago.com.br',\n",
    "#                                              'dayanrapha@gmail.com')\n",
    "#oficios_email['EMAIL_CASO_CALC'] = 'daniel.damasceno@mercadolivre.com'\n",
    "#oficios_email['EMAIL_CASO_CALC'] = 'ext_gbaranda@mercadolivre.com'\n",
    "oficios_email['EMAIL_CASO_CALC'] = 'ext_svieirad@mercadolibre.com'\n",
    "#oficios_email['EMAIL_CASO_CALC'] = 'gabriel.matias@mercadolivre.com'\n",
    "#oficios_email['EMAIL_CASO_CALC'] = 'andrielly.ribeiro@mercadolivre.com'\n",
    "#oficios_email['EMAIL_CASO_CALC'] = 'raphael.dayan@mercadopago.com.br'\n",
    "oficios_email['ARCHIVE_NAME_XLSX'] = oficios_email['OFICIO_NUMBER'].map(str) + '.xlsx'\n",
    "oficios_email['LINK_ATTACH_XLSX'] = '/alloc/data/fury_oficios-quebra-sigilo/notebooks/Archives/' + oficios_email['OFICIO_NUMBER'].map(str) + '.xlsx'\n",
    "oficios_email['ARCHIVE_NAME_AG'] = oficios_email['OFICIO_NUMBER'].map(str) + '_AGENCIAS.txt'\n",
    "oficios_email['LINK_ATTACH_AG'] = '/alloc/data/fury_oficios-quebra-sigilo/notebooks/Archives/' + oficios_email['OFICIO_NUMBER'].map(str) + '_AGENCIAS.txt'\n",
    "oficios_email['ARCHIVE_NAME_CO'] = oficios_email['OFICIO_NUMBER'].map(str) + '_CONTAS.txt'\n",
    "oficios_email['LINK_ATTACH_CO'] = '/alloc/data/fury_oficios-quebra-sigilo/notebooks/Archives/' + oficios_email['OFICIO_NUMBER'].map(str) + '_CONTAS.txt'\n",
    "oficios_email['ARCHIVE_NAME_EX'] = oficios_email['OFICIO_NUMBER'].map(str) + '_EXTRATO.txt'\n",
    "oficios_email['LINK_ATTACH_EX'] = '/alloc/data/fury_oficios-quebra-sigilo/notebooks/Archives/' + oficios_email['OFICIO_NUMBER'].map(str) + '_EXTRATO.txt'\n",
    "oficios_email['ARCHIVE_NAME_OD'] = oficios_email['OFICIO_NUMBER'].map(str) + '_ORIGEM_DESTINO.txt'\n",
    "oficios_email['LINK_ATTACH_OD'] = '/alloc/data/fury_oficios-quebra-sigilo/notebooks/Archives/' + oficios_email['OFICIO_NUMBER'].map(str) + '_ORIGEM_DESTINO.txt'\n",
    "oficios_email['ARCHIVE_NAME_TI'] = oficios_email['OFICIO_NUMBER'].map(str) + '_TITULARES.txt'\n",
    "oficios_email['LINK_ATTACH_TI'] = '/alloc/data/fury_oficios-quebra-sigilo/notebooks/Archives/' + oficios_email['OFICIO_NUMBER'].map(str) + '_TITULARES.txt'\n",
    "oficios_email['ARCHIVE_NAME_INV'] = oficios_email['OFICIO_NUMBER'].map(str) + '_INVESTIGADO.txt'\n",
    "oficios_email['LINK_ATTACH_INV'] = '/alloc/data/fury_oficios-quebra-sigilo/notebooks/Archives/' + oficios_email['OFICIO_NUMBER'].map(str) + '_INVESTIGADO.txt'\n",
    "print('Job has finished sucessfully', dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 2 factor auth, \n",
    "    # 1. Log-in into Gmail with your account\n",
    "    # 2. Navigate to https://security.google.com/settings/security/apppasswords\n",
    "    # 3. In 'select app' choose 'custom', give it an arbitrary name and press generate\n",
    "    # 4. It will give you 16 chars token.\n",
    "# Made based on https://realpython.com/python-send-email/\n",
    "\n",
    "\n",
    "# Generate email \n",
    "import smtplib, ssl\n",
    "from email.mime.text import MIMEText\n",
    "from email.utils import formataddr\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.base import MIMEBase\n",
    "from email import encoders\n",
    "\n",
    "# User configuration\n",
    "sender_email = 'raphael.dayan@mercadopago.com.br'\n",
    "sender_name = 'Mercado Pago Simba'\n",
    "password = 'jjgzaqrjkpbfjqrw'\n",
    "\n",
    "receiver_emails = oficios_email['EMAIL_CASO_CALC']\n",
    "receiver_names = oficios_email['NOME_MAGISTRADO']\n",
    "receiver_cargos = oficios_email['CARGO_MAGISTRADO']\n",
    "receiver_datas = oficios_email['DATA_OFICIO']\n",
    "receiver_tribunais = oficios_email['NOME_TRIBUNAL']\n",
    "receiver_subjects = oficios_email['OFICIO_NUMBER']\n",
    "receiver_processos = oficios_email['NUMERO_PROCESSO']\n",
    "receiver_attachments_xlsx = oficios_email['LINK_ATTACH_XLSX']\n",
    "receiver_archives_xlsx = oficios_email['ARCHIVE_NAME_XLSX']\n",
    "receiver_attachments_ag = oficios_email['LINK_ATTACH_AG']\n",
    "receiver_archives_ag = oficios_email['ARCHIVE_NAME_AG']\n",
    "receiver_attachments_co = oficios_email['LINK_ATTACH_CO']\n",
    "receiver_archives_co = oficios_email['ARCHIVE_NAME_CO']\n",
    "receiver_attachments_ex = oficios_email['LINK_ATTACH_EX']\n",
    "receiver_archives_ex= oficios_email['ARCHIVE_NAME_EX']\n",
    "receiver_attachments_od = oficios_email['LINK_ATTACH_OD']\n",
    "receiver_archives_od= oficios_email['ARCHIVE_NAME_OD']\n",
    "receiver_attachments_ti = oficios_email['LINK_ATTACH_TI']\n",
    "receiver_archives_ti= oficios_email['ARCHIVE_NAME_TI']\n",
    "receiver_attachments_inv = oficios_email['LINK_ATTACH_INV']\n",
    "receiver_archives_inv= oficios_email['ARCHIVE_NAME_INV']\n",
    "\n",
    "print('Sending email...')\n",
    "\n",
    "for receiver_email, receiver_name, receiver_subject, receiver_attachment_xlsx, receiver_archive_xlsx, receiver_cargo, receiver_data, receiver_tribunal, receiver_processo, receiver_attachment_ag, receiver_archive_ag, receiver_attachment_co, receiver_archive_co, receiver_attachment_ex, receiver_archive_ex, receiver_attachment_od, receiver_archive_od, receiver_attachment_ti, receiver_archive_ti, receiver_attachment_inv, receiver_archive_inv, in zip(receiver_emails, receiver_names, receiver_subjects, receiver_attachments_xlsx, receiver_archives_xlsx, receiver_cargos, receiver_datas, receiver_tribunais, receiver_processos, receiver_attachments_ag, receiver_archives_ag, receiver_attachments_co, receiver_archives_co, receiver_attachments_ex, receiver_archives_ex, receiver_attachments_od, receiver_archives_od, receiver_attachments_ti, receiver_archives_ti, receiver_attachments_inv, receiver_archives_inv):\n",
    "    # Email body\n",
    "    email_body = \"\"\"\\\n",
    "    <html>\n",
    "          <body>\n",
    "                <p>À {receiver_tribunal},  {receiver_cargo} {receiver_name}. <br><br>\n",
    "                   Segue resposta ao Ofício Número {receiver_subject},  processo {receiver_processo} do dia  {receiver_data}.<br><br>\n",
    "                    Pedimos-lhe desculpas pelo inconveniente e atraso na resposta ao Ofício supracitado.<br><br>\n",
    "                    A Instituição recentemente integrou-se ao processo de CCS e BACENJUD junto ao Banco Central do Brasil, e algumas demandas ainda estão internamente em processo de estruturação e adequação para melhor atender-lhes.<br><br>\n",
    "                    Neste contexto, objetivando atendê-los o mais breve possível, enviamo-lhes em anexo as informações solicitadas.<br><br>\n",
    "                    Equipe Mercado Pago Simba.\n",
    "               </p>\n",
    "          </body>\n",
    "        </html>\n",
    "    \"\"\".format(receiver_name=receiver_name, receiver_subject=receiver_subject, receiver_tribunal=receiver_tribunal, receiver_cargo=receiver_cargo, receiver_data=receiver_data, receiver_processo=receiver_processo)\n",
    "    # Configurating the email information\n",
    "    msg = MIMEMultipart()\n",
    "    msg['To'] = formataddr((receiver_name, receiver_email))\n",
    "    msg['From'] = formataddr((sender_name, sender_email))\n",
    "    msg['Subject'] = 'Resposta a Cooperação Técnica ' + receiver_subject\n",
    "    \n",
    "    msg.attach(MIMEText(email_body, 'html'))\n",
    "    \n",
    "    filename_xlsx = receiver_attachment_xlsx\n",
    "    filename_ag = receiver_attachment_ag\n",
    "    filename_co = receiver_attachment_co\n",
    "    filename_ex = receiver_attachment_ex\n",
    "    filename_od = receiver_attachment_od\n",
    "    filename_ti = receiver_attachment_ti\n",
    "    filename_inv = receiver_attachment_inv\n",
    "    try:\n",
    "        with open(filename_xlsx, 'rb') as attachment_xlsx:\n",
    "            part_xlsx = MIMEBase(\"application\", \"octet-stream\")\n",
    "            part_xlsx.set_payload(attachment_xlsx.read())\n",
    "\n",
    "        # Encode file in ASCII characters to send by email    \n",
    "        encoders.encode_base64(part_xlsx)\n",
    "\n",
    "        # Add header as key/value pair to attachment part\n",
    "        part_xlsx.add_header(\"Content-Disposition\",\n",
    "                            f\"attachment; filename= {receiver_archive_xlsx}\",)\n",
    "            \n",
    "        msg.attach(part_xlsx)\n",
    "        \n",
    "        with open(filename_ag, 'rb') as attachment_ag:\n",
    "            part_ag = MIMEBase(\"application\", \"octet-stream\")\n",
    "            part_ag.set_payload(attachment_ag.read())\n",
    "\n",
    "        # Encode file in ASCII characters to send by email    \n",
    "        encoders.encode_base64(part_ag)\n",
    "\n",
    "        # Add header as key/value pair to attachment part\n",
    "        part_ag.add_header(\"Content-Disposition\",\n",
    "                            f\"attachment; filename= {receiver_archive_ag}\",)\n",
    "            \n",
    "        msg.attach(part_ag)        \n",
    "\n",
    "        with open(filename_co, 'rb') as attachment_co:\n",
    "            part_co = MIMEBase(\"application\", \"octet-stream\")\n",
    "            part_co.set_payload(attachment_co.read())\n",
    "\n",
    "        # Encode file in ASCII characters to send by email    \n",
    "        encoders.encode_base64(part_co)\n",
    "\n",
    "        # Add header as key/value pair to attachment part\n",
    "        part_co.add_header(\"Content-Disposition\",\n",
    "                            f\"attachment; filename= {receiver_archive_co}\",)\n",
    "            \n",
    "        msg.attach(part_co)           \n",
    "        \n",
    "        with open(filename_ex, 'rb') as attachment_ex:\n",
    "            part_ex = MIMEBase(\"application\", \"octet-stream\")\n",
    "            part_ex.set_payload(attachment_ex.read())\n",
    "\n",
    "        # Encode file in ASCII characters to send by email    \n",
    "        encoders.encode_base64(part_ex)\n",
    "\n",
    "        # Add header as key/value pair to attachment part\n",
    "        part_ex.add_header(\"Content-Disposition\",\n",
    "                            f\"attachment; filename= {receiver_archive_ex}\",)\n",
    "            \n",
    "        msg.attach(part_ex)           \n",
    "        \n",
    "        with open(filename_od, 'rb') as attachment_od:\n",
    "            part_od = MIMEBase(\"application\", \"octet-stream\")\n",
    "            part_od.set_payload(attachment_od.read())\n",
    "\n",
    "        # Encode file in ASCII characters to send by email    \n",
    "        encoders.encode_base64(part_od)\n",
    "\n",
    "        # Add header as key/value pair to attachment part\n",
    "        part_od.add_header(\"Content-Disposition\",\n",
    "                            f\"attachment; filename= {receiver_archive_od}\",)\n",
    "            \n",
    "        msg.attach(part_od)           \n",
    "        \n",
    "        with open(filename_ti, 'rb') as attachment_ti:\n",
    "            part_ti = MIMEBase(\"application\", \"octet-stream\")\n",
    "            part_ti.set_payload(attachment_ti.read())\n",
    "\n",
    "        # Encode file in ASCII characters to send by email    \n",
    "        encoders.encode_base64(part_ti)\n",
    "\n",
    "        # Add header as key/value pair to attachment part\n",
    "        part_ti.add_header(\"Content-Disposition\",\n",
    "                            f\"attachment; filename= {receiver_archive_ti}\",)\n",
    "            \n",
    "        msg.attach(part_ti)   \n",
    "        \n",
    "        with open(filename_inv, 'rb') as attachment_inv:\n",
    "            part_inv = MIMEBase(\"application\", \"octet-stream\")\n",
    "            part_inv.set_payload(attachment_inv.read())\n",
    "\n",
    "        # Encode file in ASCII characters to send by email    \n",
    "        encoders.encode_base64(part_inv)\n",
    "\n",
    "        # Add header as key/value pair to attachment part\n",
    "        part_inv.add_header(\"Content-Disposition\",\n",
    "                            f\"attachment; filename= {receiver_archive_inv}\",)\n",
    "            \n",
    "        msg.attach(part_inv)  \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'Oops something went wrong in attachment\\n{e}')\n",
    "\n",
    "    try:\n",
    "        # Creating a SMTP connection\n",
    "        server = smtplib.SMTP(\"smtp.gmail.com\", 587)\n",
    "        # Encryps the email\n",
    "        context = ssl.create_default_context()\n",
    "        server.starttls(context=context)\n",
    "        # Log in into email account\n",
    "        server.login(sender_email, password)\n",
    "        # Send the email\n",
    "        server.sendmail(sender_email, receiver_email, msg.as_string())\n",
    "        print(\"Email successfully sent to\", receiver_email, ', Ofício:', receiver_subject)\n",
    "        \n",
    "        del msg\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'Oops something went wrong\\n{e}')\n",
    "    finally:\n",
    "        print('Closing the server...')\n",
    "        server.quit()\n",
    "        \n",
    "print('Job has finished sucessfully', dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lister information \n",
    "with open(\"./Queries/lister.sql\", \"r\") as f:\n",
    "    lister_response = f.read().split(\";\")[:-1]\n",
    "    \n",
    "    for query in lister_response:\n",
    "        lister_tbl = tera.execute_response(query)\n",
    "        lister_df = pd.DataFrame(lister_tbl)\n",
    "        \n",
    "lister_csv = lister_df.astype({'MOV_MOVE_ID': str,\n",
    "                                'PAY_PAYMENT_ID': str,\n",
    "                                'PAY_REASON_ID': str,\n",
    "                                'MOV_CREATED_DT': str,\n",
    "                                'MOV_CREATED_DT_CALC': str,\n",
    "                                'MOV_DETAIL': str,\n",
    "                                'OFICIO_NUMBER': str,\n",
    "                                'OFICIO_CREATED_AT': str,\n",
    "                                'MOV_TYPE_ID': str,\n",
    "                                'PAY_OPERATION_TYPE_ID': str,\n",
    "                                'MOV_FINANCIAL_ENTITY_ID': str,\n",
    "                                'WIT_WITHDRAW_ID': str,\n",
    "                                'MOV_AMOUNT': str,\n",
    "                                'MOV_AMOUNT_CALC': str,\n",
    "                                'ACCOUNT_TYPE': str,\n",
    "                                'WIT_BANK_ACC_NUMBER': str,\n",
    "                                'WITHDRAWAL_STATUS': str,\n",
    "                                'RECEIVING_ACCOUNT_HOLDER_NAME': str,\n",
    "                                'RECEIVING_ACCOUNT_HOLDER_DOC_NUMBER': str,\n",
    "                                'BANK_ID': str,\n",
    "                                'WIT_BANK_ACC_BRANCH_ID': str,\n",
    "                                'RECEIVING_BANK_NAME': str,\n",
    "                                'PAYER_BANK_NAME': str,\n",
    "                                'WITHDRAWAL_METHOD': str,\n",
    "                                'WITHDRAWAL_AMOUNT': str,\n",
    "                                'CUS_CUST_ID': str,\n",
    "                                'CUS_FULL_NAME': str,\n",
    "                                'CUS_CUST_DOC_NUMBER': str,\n",
    "                                'CUS_CUST_DOC_TYPE': str,\n",
    "                                'CUS_ADDRESS': str,\n",
    "                                'CUS_RU_SINCE_DT': str,\n",
    "                                'CUS_RU_SINCE_DT_MP': str,\n",
    "                                'CUS_CUST_STATUS_MP': str,\n",
    "                                'CUS_PHONE': str,\n",
    "                                'CUS_COUNTRY': str,\n",
    "                                'CUS_STATE': str,\n",
    "                                'CUS_CITY': str,\n",
    "                                'CUS_ZIP_CODE': str,\n",
    "                                'CUS_CUST_ID_BUY': str,\n",
    "                                'CUS_FULL_NAME_BUY': str,\n",
    "                                'CUS_CUST_DOC_NUMBER_BUY': str,\n",
    "                                'CUS_CUST_DOC_TYPE_BUY': str,\n",
    "                                'CUS_ADDRESS_BUY': str,\n",
    "                                'CUS_RU_SINCE_DT_BUY': str,\n",
    "                                'CUS_RU_SINCE_DT_MP_BUY': str,\n",
    "                                'CUS_CUST_STATUS_MP_BUY': str,\n",
    "                                'CUS_PHONE_BUY': str,\n",
    "                                'CUS_COUNTRY_BUY': str,\n",
    "                                'CUS_STATE_BUY': str,\n",
    "                                'UF': str,\n",
    "                                'CUS_CITY_BUY': str,\n",
    "                                'CUS_ZIP_CODE_BUY': str,\n",
    "                                'CUS_CUST_ID_SEL': str,\n",
    "                                'CUS_FULL_NAME_SEL': str,\n",
    "                                'CUS_CUST_DOC_NUMBER_SEL': str,\n",
    "                                'CUS_CUST_DOC_TYPE_SEL': str,\n",
    "                                'CUS_ADDRESS_SEL': str,\n",
    "                                'CUS_RU_SINCE_DT_SEL': str,\n",
    "                                'CUS_RU_SINCE_DT_MP_SEL': str,\n",
    "                                'CUS_CUST_STATUS_MP_SEL': str,\n",
    "                                'CUS_PHONE_SEL': str,\n",
    "                                'CUS_COUNTRY_SEL': str,\n",
    "                                'CUS_STATE_SEL': str,\n",
    "                                'CUS_CITY_SEL': str,\n",
    "                                'CUS_ZIP_CODE_SEL': str,\n",
    "                                'GENERATED_AT': str,\n",
    "                                'HAD_REPORT': str})\n",
    "\n",
    "lister_csv = lister_csv[['CUS_CUST_DOC_NUMBER', 'CUS_CUST_ID_BUY', 'CUS_FULL_NAME', 'CUS_CUST_DOC_NUMBER_SEL',\n",
    "                         'CUS_CUST_ID_SEL', 'CUS_FULL_NAME_SEL', 'MOV_MOVE_ID', 'PAY_PAYMENT_ID', 'MOV_CREATED_DT',\n",
    "                         'PAY_REASON_ID', 'MOV_DETAIL', 'PAY_OPERATION_TYPE_ID', 'MOV_AMOUNT', 'WIT_WITHDRAW_ID',\n",
    "                         'ACCOUNT_TYPE', 'WIT_BANK_ACC_NUMBER', 'RECEIVING_ACCOUNT_HOLDER_NAME', 'RECEIVING_ACCOUNT_HOLDER_DOC_NUMBER',\n",
    "                         'BANK_ID', 'WIT_BANK_ACC_BRANCH_ID', 'RECEIVING_BANK_NAME', 'OFICIO_NUMBER']]\n",
    "\n",
    "lister_csv = lister_csv.rename(columns={'CUS_CUST_DOC_NUMBER': 'Documento Origem (Investigado)',\n",
    "                                        'CUS_CUST_ID_BUY': 'ID Interno  Origem (Investigado)',\n",
    "                                        'CUS_FULL_NAME': 'Nome Registro Origem (Investigado)',\n",
    "                                        'CUS_CUST_DOC_NUMBER_SEL': 'Documento Destino  (Contraparte)',\n",
    "                                        'CUS_CUST_ID_SEL': 'ID Interno  Destino (Contraparte)',\n",
    "                                        'CUS_FULL_NAME_SEL': 'Nome Registro Destino (Contraparte)',\n",
    "                                        'MOV_MOVE_ID': 'ID Movimentação Interno',\n",
    "                                        'PAY_PAYMENT_ID': 'ID Pagamento Interno',\n",
    "                                        'MOV_CREATED_DT': 'Data Movimentação',\n",
    "                                        'PAY_REASON_ID': 'Descrição da Movimentação',\n",
    "                                        'MOV_DETAIL': 'Tipo  Movimentação',\n",
    "                                        'PAY_OPERATION_TYPE_ID': 'Detalhe Movimentação',\n",
    "                                        'MOV_AMOUNT': 'Valor  Movimentação',\n",
    "                                        'WIT_WITHDRAW_ID': 'ID Saque Interno',\n",
    "                                        'ACCOUNT_TYPE': 'Tipo Conta Bancária',\n",
    "                                        'WIT_BANK_ACC_NUMBER': 'Número Conta',\n",
    "                                        'RECEIVING_ACCOUNT_HOLDER_NAME': 'Nome Recebedor Saque',\n",
    "                                        'RECEIVING_ACCOUNT_HOLDER_DOC_NUMBER': 'Documento Recebedor',\n",
    "                                        'BANK_ID': 'Banco Recebedor',\n",
    "                                        'WIT_BANK_ACC_BRANCH_ID': 'Número Agência',\n",
    "                                        'RECEIVING_BANK_NAME': 'Número Agência',\n",
    "                                        'OFICIO_NUMBER': 'OFICIO_NUMBER'})\n",
    "\n",
    "lister_csv.to_excel('/alloc/data/fury_oficios-quebra-sigilo/notebooks/casos.xlsx', index= False, header = True)\n",
    "\n",
    "print(lister_df.shape, dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
